# æ”¹è¿›yolo11-DBBNCSPELANç­‰200+å…¨å¥—åˆ›æ–°ç‚¹å¤§å…¨ï¼šæ‚è‰æ£€æµ‹ç³»ç»Ÿæºç ï¼†æ•°æ®é›†å…¨å¥—

### 1.å›¾ç‰‡æ•ˆæœå±•ç¤º

![1.png](1.png)

![2.png](2.png)

![3.png](3.png)

##### é¡¹ç›®æ¥æº **[äººå·¥æ™ºèƒ½ä¿ƒè¿›ä¼š 2024.10.30](https://kdocs.cn/l/cszuIiCKVNis)**

æ³¨æ„ï¼šç”±äºé¡¹ç›®ä¸€ç›´åœ¨æ›´æ–°è¿­ä»£ï¼Œä¸Šé¢â€œ1.å›¾ç‰‡æ•ˆæœå±•ç¤ºâ€å’Œâ€œ2.è§†é¢‘æ•ˆæœå±•ç¤ºâ€å±•ç¤ºçš„ç³»ç»Ÿå›¾ç‰‡æˆ–è€…è§†é¢‘å¯èƒ½ä¸ºè€ç‰ˆæœ¬ï¼Œæ–°ç‰ˆæœ¬åœ¨è€ç‰ˆæœ¬çš„åŸºç¡€ä¸Šå‡çº§å¦‚ä¸‹ï¼šï¼ˆå®é™…æ•ˆæœä»¥å‡çº§çš„æ–°ç‰ˆæœ¬ä¸ºå‡†ï¼‰

  ï¼ˆ1ï¼‰é€‚é…äº†YOLOV11çš„â€œç›®æ ‡æ£€æµ‹â€æ¨¡å‹å’Œâ€œå®ä¾‹åˆ†å‰²â€æ¨¡å‹ï¼Œé€šè¿‡åŠ è½½ç›¸åº”çš„æƒé‡ï¼ˆ.ptï¼‰æ–‡ä»¶å³å¯è‡ªé€‚åº”åŠ è½½æ¨¡å‹ã€‚

  ï¼ˆ2ï¼‰æ”¯æŒâ€œå›¾ç‰‡è¯†åˆ«â€ã€â€œè§†é¢‘è¯†åˆ«â€ã€â€œæ‘„åƒå¤´å®æ—¶è¯†åˆ«â€ä¸‰ç§è¯†åˆ«æ¨¡å¼ã€‚

  ï¼ˆ3ï¼‰æ”¯æŒâ€œå›¾ç‰‡è¯†åˆ«â€ã€â€œè§†é¢‘è¯†åˆ«â€ã€â€œæ‘„åƒå¤´å®æ—¶è¯†åˆ«â€ä¸‰ç§è¯†åˆ«ç»“æœä¿å­˜å¯¼å‡ºï¼Œè§£å†³æ‰‹åŠ¨å¯¼å‡ºï¼ˆå®¹æ˜“å¡é¡¿å‡ºç°çˆ†å†…å­˜ï¼‰å­˜åœ¨çš„é—®é¢˜ï¼Œè¯†åˆ«å®Œè‡ªåŠ¨ä¿å­˜ç»“æœå¹¶å¯¼å‡ºåˆ°tempDirä¸­ã€‚

  ï¼ˆ4ï¼‰æ”¯æŒWebå‰ç«¯ç³»ç»Ÿä¸­çš„æ ‡é¢˜ã€èƒŒæ™¯å›¾ç­‰è‡ªå®šä¹‰ä¿®æ”¹ã€‚

  å¦å¤–æœ¬é¡¹ç›®æä¾›è®­ç»ƒçš„æ•°æ®é›†å’Œè®­ç»ƒæ•™ç¨‹,æš‚ä¸æä¾›æƒé‡æ–‡ä»¶ï¼ˆbest.ptï¼‰,éœ€è¦æ‚¨æŒ‰ç…§æ•™ç¨‹è¿›è¡Œè®­ç»ƒåå®ç°å›¾ç‰‡æ¼”ç¤ºå’ŒWebå‰ç«¯ç•Œé¢æ¼”ç¤ºçš„æ•ˆæœã€‚

### 2.è§†é¢‘æ•ˆæœå±•ç¤º

[2.1 è§†é¢‘æ•ˆæœå±•ç¤º](https://www.bilibili.com/video/BV1pPSqYzEFc/)

### 3.èƒŒæ™¯

ç ”ç©¶èƒŒæ™¯ä¸æ„ä¹‰

éšç€å…¨çƒå†œä¸šç”Ÿäº§çš„ä¸æ–­å‘å±•ï¼Œæ‚è‰çš„ç®¡ç†ä¸æ§åˆ¶å·²æˆä¸ºæé«˜ä½œç‰©äº§é‡å’Œè´¨é‡çš„é‡è¦ç¯èŠ‚ã€‚æ‚è‰ä¸ä»…ä¼šä¸ä½œç‰©äº‰å¤ºæ°´åˆ†ã€å…»åˆ†å’Œå…‰ç…§ï¼Œè¿˜å¯èƒ½æˆä¸ºç—…è™«å®³çš„æ»‹ç”Ÿåœ°ï¼Œä»è€Œå¯¹å†œä¸šç”Ÿäº§é€ æˆä¸¥é‡å½±å“ã€‚å› æ­¤ï¼ŒåŠæ—¶ã€å‡†ç¡®åœ°è¯†åˆ«å’Œå¤„ç†æ‚è‰æ˜¯ç°ä»£å†œä¸šç®¡ç†ä¸­ä¸å¯æˆ–ç¼ºçš„ä¸€éƒ¨åˆ†ã€‚ä¼ ç»Ÿçš„æ‚è‰æ£€æµ‹æ–¹æ³•å¤šä¾èµ–äººå·¥è¯†åˆ«ï¼Œæ•ˆç‡ä½ä¸‹ä¸”å®¹æ˜“å—åˆ°ä¸»è§‚å› ç´ çš„å½±å“ã€‚è¿‘å¹´æ¥ï¼Œéšç€è®¡ç®—æœºè§†è§‰å’Œæ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼ŒåŸºäºå›¾åƒè¯†åˆ«çš„æ‚è‰æ£€æµ‹ç³»ç»Ÿé€æ¸æˆä¸ºç ”ç©¶çƒ­ç‚¹ã€‚

æœ¬ç ”ç©¶æ—¨åœ¨åŸºäºæ”¹è¿›çš„YOLOv11æ¨¡å‹ï¼Œæ„å»ºä¸€ä¸ªé«˜æ•ˆçš„æ‚è‰æ£€æµ‹ç³»ç»Ÿã€‚YOLOï¼ˆYou Only Look Onceï¼‰ç³»åˆ—æ¨¡å‹ä»¥å…¶å®æ—¶æ€§å’Œé«˜å‡†ç¡®ç‡åœ¨ç›®æ ‡æ£€æµ‹é¢†åŸŸå–å¾—äº†æ˜¾è‘—æˆæœã€‚YOLOv11ä½œä¸ºæœ€æ–°ç‰ˆæœ¬ï¼Œç»“åˆäº†å¤šç§å…ˆè¿›çš„ç½‘ç»œç»“æ„å’Œä¼˜åŒ–ç®—æ³•ï¼Œå…·æœ‰æ›´å¼ºçš„ç‰¹å¾æå–èƒ½åŠ›å’Œæ›´å¿«çš„æ¨ç†é€Ÿåº¦ã€‚ç„¶è€Œï¼Œç°æœ‰çš„YOLOv11æ¨¡å‹åœ¨ç‰¹å®šçš„å†œä¸šåº”ç”¨åœºæ™¯ä¸­ä»å­˜åœ¨ä¸€å®šçš„å±€é™æ€§ï¼Œå°¤å…¶æ˜¯åœ¨æ‚è‰ç§ç±»å¤šæ ·ã€ç¯å¢ƒå¤æ‚çš„æƒ…å†µä¸‹ã€‚å› æ­¤ï¼Œé’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæœ¬ç ”ç©¶å°†å¯¹YOLOv11è¿›è¡Œæ”¹è¿›ï¼Œä»¥æé«˜å…¶åœ¨æ‚è‰æ£€æµ‹ä¸­çš„æ€§èƒ½ã€‚

æœ¬ç ”ç©¶æ‰€ä½¿ç”¨çš„æ•°æ®é›†â€œfull_width_weedsâ€åŒ…å«120å¹…å›¾åƒï¼Œå°½ç®¡æ ·æœ¬æ•°é‡ç›¸å¯¹è¾ƒå°‘ï¼Œä½†å…¶åœ¨ç›®æ ‡æ£€æµ‹ä¸­çš„åº”ç”¨æ½œåŠ›ä¸å®¹å¿½è§†ã€‚é€šè¿‡å¯¹è¯¥æ•°æ®é›†çš„æ·±å…¥åˆ†æä¸å¤„ç†ï¼Œç»“åˆæ”¹è¿›åçš„YOLOv11æ¨¡å‹ï¼ŒæœŸæœ›èƒ½å¤Ÿå®ç°å¯¹ä¸åŒç±»å‹æ‚è‰çš„å‡†ç¡®è¯†åˆ«ä¸åˆ†ç±»ï¼Œä»è€Œä¸ºå†œä¸šç”Ÿäº§æä¾›æœ‰æ•ˆçš„æŠ€æœ¯æ”¯æŒã€‚è¿™ä¸ä»…æœ‰åŠ©äºæå‡æ‚è‰ç®¡ç†çš„æ•ˆç‡ï¼Œè¿˜å°†æ¨åŠ¨æ™ºèƒ½å†œä¸šçš„å‘å±•ï¼Œä¸ºå®ç°å¯æŒç»­å†œä¸šç”Ÿäº§æä¾›æ–°çš„è§£å†³æ–¹æ¡ˆã€‚

### 4.æ•°æ®é›†ä¿¡æ¯å±•ç¤º

##### 4.1 æœ¬é¡¹ç›®æ•°æ®é›†è¯¦ç»†æ•°æ®ï¼ˆç±»åˆ«æ•°ï¼†ç±»åˆ«åï¼‰

nc: 1
names: ['weed-location']



è¯¥é¡¹ç›®ä¸ºã€ç›®æ ‡æ£€æµ‹ã€‘æ•°æ®é›†ï¼Œè¯·åœ¨ã€è®­ç»ƒæ•™ç¨‹å’ŒWebç«¯åŠ è½½æ¨¡å‹æ•™ç¨‹ï¼ˆç¬¬ä¸‰æ­¥ï¼‰ã€‘è¿™ä¸€æ­¥çš„æ—¶å€™æŒ‰ç…§ã€ç›®æ ‡æ£€æµ‹ã€‘éƒ¨åˆ†çš„æ•™ç¨‹æ¥è®­ç»ƒ

##### 4.2 æœ¬é¡¹ç›®æ•°æ®é›†ä¿¡æ¯ä»‹ç»

æœ¬é¡¹ç›®æ•°æ®é›†ä¿¡æ¯ä»‹ç»

æœ¬é¡¹ç›®æ‰€ä½¿ç”¨çš„æ•°æ®é›†åä¸ºâ€œfull_width_weedsâ€ï¼Œæ—¨åœ¨ä¸ºæ”¹è¿›YOLOv11çš„æ‚è‰æ£€æµ‹ç³»ç»Ÿæä¾›é«˜è´¨é‡çš„è®­ç»ƒæ•°æ®ã€‚è¯¥æ•°æ®é›†ä¸“æ³¨äºå•ä¸€ç±»åˆ«çš„æ‚è‰å®šä½ï¼ŒåŒ…å«äº†ä¸°å¯Œçš„æ ·æœ¬ï¼Œä»¥æ”¯æŒæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å¤æ‚ç¯å¢ƒä¸­çš„è¡¨ç°ã€‚æ•°æ®é›†ä¸­ç±»åˆ«æ•°é‡ä¸º1ï¼Œå…·ä½“ç±»åˆ«ä¸ºâ€œweed-locationâ€ï¼Œè¿™ä¸€ç±»åˆ«æ¶µç›–äº†å¤šç§ä¸åŒç±»å‹çš„æ‚è‰åœ¨ä¸åŒç”Ÿé•¿é˜¶æ®µå’Œç¯å¢ƒæ¡ä»¶ä¸‹çš„è¡¨ç°ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«å’Œå®šä½æ‚è‰ã€‚

â€œfull_width_weedsâ€æ•°æ®é›†çš„æ„å»ºè¿‡ç¨‹ç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œæ¶µç›–äº†å¤šæ ·åŒ–çš„åœºæ™¯ï¼ŒåŒ…æ‹¬åŸå¸‚ç»¿åœ°ã€å†œç”°ã€è‰åªç­‰å¤šç§ç¯å¢ƒï¼Œä»¥æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚æ•°æ®é›†ä¸­æ¯ä¸ªæ ·æœ¬å‡ç»è¿‡æ ‡æ³¨ï¼Œç¡®ä¿åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹èƒ½å¤Ÿå‡†ç¡®å­¦ä¹ åˆ°æ‚è‰çš„ç‰¹å¾ã€‚è¿™äº›æ ·æœ¬ä¸ä»…åŒ…æ‹¬æ‚è‰çš„æ•´ä½“å›¾åƒï¼Œè¿˜åŒ…æ‹¬ç‰¹å®šåŒºåŸŸçš„æ”¾å¤§å›¾ï¼Œä»¥ä¾¿äºæ¨¡å‹åœ¨ç»†èŠ‚è¯†åˆ«ä¸Šè¿›è¡Œæ›´æ·±å…¥çš„å­¦ä¹ ã€‚

æ­¤å¤–ï¼Œæ•°æ®é›†çš„é‡‡é›†è¿‡ç¨‹éµå¾ªä¸¥æ ¼çš„æ ‡å‡†ï¼Œç¡®ä¿äº†æ•°æ®çš„å¤šæ ·æ€§å’Œä»£è¡¨æ€§ã€‚æ ·æœ¬çš„æ‹æ‘„æ—¶é—´ã€å…‰ç…§æ¡ä»¶ã€å¤©æ°”å˜åŒ–ç­‰å› ç´ å‡è¢«è€ƒè™‘åœ¨å†…ï¼Œä»¥æ¨¡æ‹Ÿå®é™…åº”ç”¨ä¸­çš„å„ç§æŒ‘æˆ˜ã€‚è¿™ç§å…¨é¢çš„è®¾è®¡ç†å¿µæ—¨åœ¨æå‡YOLOv11åœ¨æ‚è‰æ£€æµ‹ä»»åŠ¡ä¸­çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

é€šè¿‡ä½¿ç”¨â€œfull_width_weedsâ€æ•°æ®é›†ï¼Œæˆ‘ä»¬æœŸæœ›åœ¨æ‚è‰æ£€æµ‹é¢†åŸŸå–å¾—æ˜¾è‘—çš„è¿›å±•ï¼Œæ¨åŠ¨æ™ºèƒ½å†œä¸šå’Œç¯å¢ƒç›‘æµ‹æŠ€æœ¯çš„å‘å±•ï¼Œä¸ºå®ç°ç²¾å‡†å†œä¸šæä¾›æœ‰åŠ›æ”¯æŒã€‚

![4.png](4.png)

![5.png](5.png)

![6.png](6.png)

![7.png](7.png)

![8.png](8.png)

### 5.å…¨å¥—é¡¹ç›®ç¯å¢ƒéƒ¨ç½²è§†é¢‘æ•™ç¨‹ï¼ˆé›¶åŸºç¡€æ‰‹æŠŠæ‰‹æ•™å­¦ï¼‰

[5.1 æ‰€éœ€è½¯ä»¶PyCharmå’ŒAnacondaå®‰è£…æ•™ç¨‹ï¼ˆç¬¬ä¸€æ­¥ï¼‰](https://www.bilibili.com/video/BV1BoC1YCEKi/?spm_id_from=333.999.0.0&vd_source=bc9aec86d164b67a7004b996143742dc)




[5.2 å®‰è£…Pythonè™šæ‹Ÿç¯å¢ƒåˆ›å»ºå’Œä¾èµ–åº“å®‰è£…è§†é¢‘æ•™ç¨‹ï¼ˆç¬¬äºŒæ­¥ï¼‰](https://www.bilibili.com/video/BV1ZoC1YCEBw?spm_id_from=333.788.videopod.sections&vd_source=bc9aec86d164b67a7004b996143742dc)

### 6.æ”¹è¿›YOLOv11è®­ç»ƒæ•™ç¨‹å’ŒWeb_UIå‰ç«¯åŠ è½½æ¨¡å‹æ•™ç¨‹ï¼ˆé›¶åŸºç¡€æ‰‹æŠŠæ‰‹æ•™å­¦ï¼‰

[6.1 æ”¹è¿›YOLOv11è®­ç»ƒæ•™ç¨‹å’ŒWeb_UIå‰ç«¯åŠ è½½æ¨¡å‹æ•™ç¨‹ï¼ˆç¬¬ä¸‰æ­¥ï¼‰](https://www.bilibili.com/video/BV1BoC1YCEhR?spm_id_from=333.788.videopod.sections&vd_source=bc9aec86d164b67a7004b996143742dc)


æŒ‰ç…§ä¸Šé¢çš„è®­ç»ƒè§†é¢‘æ•™ç¨‹é“¾æ¥åŠ è½½é¡¹ç›®æä¾›çš„æ•°æ®é›†ï¼Œè¿è¡Œtrain.pyå³å¯å¼€å§‹è®­ç»ƒ
ï»¿


     Epoch   gpu_mem       box       obj       cls    labels  img_size
     1/200     20.8G   0.01576   0.01955  0.007536        22      1280: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [14:42<00:00,  1.04s/it]
               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 213/213 [01:14<00:00,  2.87it/s]
                 all       3395      17314      0.994      0.957      0.0957      0.0843

     Epoch   gpu_mem       box       obj       cls    labels  img_size
     2/200     20.8G   0.01578   0.01923  0.007006        22      1280: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [14:44<00:00,  1.04s/it]
               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 213/213 [01:12<00:00,  2.95it/s]
                 all       3395      17314      0.996      0.956      0.0957      0.0845

     Epoch   gpu_mem       box       obj       cls    labels  img_size
     3/200     20.8G   0.01561    0.0191  0.006895        27      1280: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [10:56<00:00,  1.29it/s]
               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 187/213 [00:52<00:00,  4.04it/s]
                 all       3395      17314      0.996      0.957      0.0957      0.0845




###### [é¡¹ç›®æ•°æ®é›†ä¸‹è½½é“¾æ¥](https://kdocs.cn/l/cszuIiCKVNis)

### 7.åŸå§‹YOLOv11ç®—æ³•è®²è§£

YOLOv11æ˜¯Ultralyticsæ¨å‡ºçš„YOLOç³»åˆ—æœ€æ–°ç‰ˆæœ¬ï¼Œä¸“ä¸ºå®ç°å°–ç«¯çš„ç‰©ä½“æ£€æµ‹è€Œè®¾è®¡ã€‚å…¶æ¶æ„å’Œè®­ç»ƒæ–¹æ³•ä¸Šè¿›è¡Œäº†é‡å¤§æ”¹è¿›ï¼Œä½¿ä¹‹ä¸ä»…å…·å¤‡å“è¶Šçš„å‡†ç¡®æ€§å’Œå¤„ç†é€Ÿåº¦ï¼Œè¿˜åœ¨è®¡ç®—æ•ˆç‡ä¸Šå®ç°äº†ä¸€åœºé©å‘½ã€‚å¾—ç›Šäºå…¶æ”¹è¿›çš„ä¸»å¹²å’Œé¢ˆéƒ¨æ¶æ„ï¼ŒYOLOv11åœ¨ç‰¹å¾æå–å’Œå¤„ç†å¤æ‚ä»»åŠ¡æ—¶è¡¨ç°æ›´åŠ å‡ºè‰²ã€‚åœ¨2024å¹´9æœˆ27æ—¥ï¼ŒUltralyticsé€šè¿‡é•¿è¾¾ä¹å°æ—¶çš„åœ¨çº¿ç›´æ’­å‘å¸ƒè¿™ä¸€æ–°ä½œï¼Œå±•ç¤ºäº†å…¶åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„é©æ–°ã€‚

YOLOv11é€šè¿‡ç²¾ç»†çš„æ¶æ„è®¾è®¡å’Œä¼˜åŒ–è®­ç»ƒæµç¨‹ï¼Œåœ¨ä¿æŒé«˜ç²¾åº¦çš„åŒæ—¶ï¼Œç¼©å‡äº†å‚æ•°é‡ï¼Œä¸YOLOv8mç›¸æ¯”å‡å°‘äº†22%çš„å‚æ•°ï¼Œä½¿å…¶åœ¨COCOæ•°æ®é›†ä¸Šçš„å¹³å‡å‡†ç¡®åº¦ï¼ˆmAPï¼‰æœ‰æ‰€æå‡ã€‚è¿™ç§æ•ˆç‡çš„æé«˜ä½¿YOLOv11éå¸¸é€‚åˆéƒ¨ç½²åœ¨å„ç§ç¡¬ä»¶ç¯å¢ƒä¸­ï¼ŒåŒ…æ‹¬è¾¹ç¼˜è®¾å¤‡ã€äº‘è®¡ç®—å¹³å°ä»¥åŠæ”¯æŒNVIDIA GPUçš„ç³»ç»Ÿï¼Œç¡®ä¿åœ¨çµæ´»æ€§ä¸Šçš„ä¼˜åŠ¿ã€‚

è¯¥æ¨¡å‹æ”¯æŒå¹¿æ³›çš„ä»»åŠ¡ï¼Œä»å¯¹è±¡æ£€æµ‹ã€å®ä¾‹åˆ†å‰²åˆ°å›¾åƒåˆ†ç±»ã€å§¿æ€ä¼°è®¡å’Œå®šå‘å¯¹è±¡æ£€æµ‹ï¼ˆOBBï¼‰ï¼Œå‡ ä¹è¦†ç›–äº†è®¡ç®—æœºè§†è§‰çš„æ‰€æœ‰ä¸»è¦æŒ‘æˆ˜ã€‚å…¶åˆ›æ–°çš„C3k2å’ŒC2PSAæ¨¡å—æå‡äº†ç½‘ç»œæ·±åº¦å’Œæ³¨æ„åŠ›æœºåˆ¶çš„åº”ç”¨ï¼Œæé«˜äº†ç‰¹å¾æå–çš„æ•ˆç‡å’Œæ•ˆæœã€‚åŒæ—¶ï¼ŒYOLOv11çš„æ”¹è¿›ç½‘ç»œç»“æ„ä¹Ÿä½¿ä¹‹åœ¨å¤æ‚è§†è§‰ä»»åŠ¡ä¸Šå¾—ä»¥ä»å®¹åº”å¯¹ï¼Œæˆä¸ºå„ç±»è®¡ç®—æœºè§†è§‰ä»»åŠ¡çš„å¤šåŠŸèƒ½é€‰æ‹©ã€‚è¿™äº›ç‰¹æ€§ä»¤YOLOv11åœ¨å®æ–½å®æ—¶ç‰©ä½“æ£€æµ‹çš„å„ä¸ªé¢†åŸŸä¸­è¡¨ç°å‡ºä¼—ã€‚
* * *

2024å¹´9æœˆ27æ—¥ï¼ŒUltralyticsåœ¨çº¿ç›´æ’­é•¿è¾¾ä¹å°æ—¶ï¼Œä¸ºYOLO11å¬å¼€â€œå‘å¸ƒä¼šâ€

YOLO11 æ˜¯ Ultralytics YOLO ç³»åˆ—å®æ—¶ç‰©ä½“æ£€æµ‹å™¨çš„æœ€æ–°ç‰ˆæœ¬ï¼Œå®ƒä»¥å°–ç«¯çš„å‡†ç¡®æ€§ã€é€Ÿåº¦å’Œæ•ˆç‡é‡æ–°å®šä¹‰äº†å¯èƒ½æ€§ã€‚åœ¨ä¹‹å‰ YOLO
ç‰ˆæœ¬çš„æ˜¾è‘—è¿›æ­¥çš„åŸºç¡€ä¸Šï¼ŒYOLO11 åœ¨æ¶æ„å’Œè®­ç»ƒæ–¹æ³•æ–¹é¢è¿›è¡Œäº†é‡å¤§æ”¹è¿›ï¼Œä½¿å…¶æˆä¸ºå„ç§è®¡ç®—æœºè§†è§‰ä»»åŠ¡çš„å¤šåŠŸèƒ½é€‰æ‹©ã€‚

![](https://i-blog.csdnimg.cn/direct/a4e1a178833746249720ccee1c82a58b.png)

##### YOLO11ä¸»è¦ç‰¹ç‚¹ï¼š

  * å¢å¼ºçš„ç‰¹å¾æå–ï¼šYOLO11 é‡‡ç”¨äº†æ”¹è¿›çš„ä¸»å¹²å’Œé¢ˆéƒ¨æ¶æ„ï¼Œå¢å¼ºäº†ç‰¹å¾æå–èƒ½åŠ›ï¼Œå¯å®ç°æ›´ç²¾ç¡®çš„å¯¹è±¡æ£€æµ‹å’Œå¤æ‚ä»»åŠ¡æ€§èƒ½ã€‚
  * é’ˆå¯¹æ•ˆç‡å’Œé€Ÿåº¦è¿›è¡Œäº†ä¼˜åŒ–ï¼šYOLO11 å¼•å…¥äº†å®Œå–„çš„æ¶æ„è®¾è®¡å’Œä¼˜åŒ–çš„è®­ç»ƒæµç¨‹ï¼Œå¯æä¾›æ›´å¿«çš„å¤„ç†é€Ÿåº¦ï¼Œå¹¶åœ¨å‡†ç¡®åº¦å’Œæ€§èƒ½ä¹‹é—´ä¿æŒæœ€ä½³å¹³è¡¡ã€‚
  * æ›´å°‘çš„å‚æ•°ï¼Œæ›´é«˜çš„å‡†ç¡®åº¦ï¼šå€ŸåŠ©æ¨¡å‹è®¾è®¡çš„è¿›æ­¥ï¼ŒYOLO11m åœ¨ COCO æ•°æ®é›†ä¸Šå®ç°äº†æ›´é«˜çš„å¹³å‡å‡†ç¡®åº¦ (mAP)ï¼ŒåŒæ—¶ä½¿ç”¨çš„å‚æ•°æ¯” YOLOv8m å°‘ 22%ï¼Œä»è€Œæé«˜äº†è®¡ç®—æ•ˆç‡ï¼ŒåŒæ—¶åˆä¸å½±å“å‡†ç¡®åº¦ã€‚
  * è·¨ç¯å¢ƒçš„é€‚åº”æ€§ï¼šYOLO11 å¯ä»¥æ— ç¼éƒ¨ç½²åœ¨å„ç§ç¯å¢ƒä¸­ï¼ŒåŒ…æ‹¬è¾¹ç¼˜è®¾å¤‡ã€äº‘å¹³å°å’Œæ”¯æŒ NVIDIA GPU çš„ç³»ç»Ÿï¼Œä»è€Œç¡®ä¿æœ€å¤§çš„çµæ´»æ€§ã€‚
  * æ”¯æŒçš„ä»»åŠ¡èŒƒå›´å¹¿æ³›ï¼šæ— è®ºæ˜¯å¯¹è±¡æ£€æµ‹ã€å®ä¾‹åˆ†å‰²ã€å›¾åƒåˆ†ç±»ã€å§¿åŠ¿ä¼°è®¡è¿˜æ˜¯å®šå‘å¯¹è±¡æ£€æµ‹ (OBB)ï¼ŒYOLO11 éƒ½æ—¨åœ¨æ»¡è¶³å„ç§è®¡ç®—æœºè§†è§‰æŒ‘æˆ˜ã€‚

##### æ”¯æŒçš„ä»»åŠ¡å’Œæ¨¡å¼

YOLO11 ä»¥ YOLOv8 ä¸­å¼•å…¥çš„å¤šåŠŸèƒ½æ¨¡å‹ç³»åˆ—ä¸ºåŸºç¡€ï¼Œä¸ºå„ç§è®¡ç®—æœºè§†è§‰ä»»åŠ¡æä¾›å¢å¼ºçš„æ”¯æŒï¼š

Model| Filenames| Task| Inference| Validation| Training| Export  
---|---|---|---|---|---|---  
YOLO11| yolol11n.pt, yolol11s.pt, yolol11m.pt, yolol11x.pt| Detection| âœ…| âœ…|
âœ…| âœ…  
YOLO11-seg| yolol11n-seg.pt, yolol11s-seg.pt, yolol11m-seg.pt,
yolol11x-seg.pt| Instance Segmentation| âœ…| âœ…| âœ…| âœ…  
YOLO11-pose| yolol11n-pose.pt, yolol11s-pose.pt, yolol11m-pose.pt,
yolol11x-pose.pt| Pose/Keypoints| âœ…| âœ…| âœ…| âœ…  
YOLO11-obb| yolol11n-obb.pt, yolol11s-obb.pt, yolol11m-obb.pt,
yolol11x-obb.pt| Oriented Detection| âœ…| âœ…| âœ…| âœ…  
YOLO11-cls| yolol11n-cls.pt, yolol11s-cls.pt, yolol11m-cls.pt,
yolol11x-cls.pt| Classification| âœ…| âœ…| âœ…| âœ…  
  
##### ç®€å•çš„ YOLO11 è®­ç»ƒå’Œæ¨ç†ç¤ºä¾‹

ä»¥ä¸‹ç¤ºä¾‹é€‚ç”¨äºç”¨äºå¯¹è±¡æ£€æµ‹çš„ YOLO11 Detect æ¨¡å‹ã€‚

    
    
    from ultralytics import YOLO
    
    # Load a model
    model = YOLO("yolo11n.pt")
    
    # Train the model
    train_results = model.train(
        data="coco8.yaml",  # path to dataset YAML
        epochs=100,  # number of training epochs
        imgsz=640,  # training image size
        device="cpu",  # device to run on, i.e. device=0 or device=0,1,2,3 or device=cpu
    )
    
    # Evaluate model performance on the validation set
    metrics = model.val()
    
    # Perform object detection on an image
    results = model("path/to/image.jpg")
    results[0].show()
    
    # Export the model to ONNX format
    path = model.export(format="onnx")  # return path to exported model

##### æ”¯æŒéƒ¨ç½²äºè¾¹ç¼˜è®¾å¤‡

YOLO11 ä¸“ä¸ºé€‚åº”å„ç§ç¯å¢ƒè€Œè®¾è®¡ï¼ŒåŒ…æ‹¬è¾¹ç¼˜è®¾å¤‡ã€‚å…¶ä¼˜åŒ–çš„æ¶æ„å’Œé«˜æ•ˆçš„å¤„ç†èƒ½åŠ›ä½¿å…¶é€‚åˆéƒ¨ç½²åœ¨è¾¹ç¼˜è®¾å¤‡ã€äº‘å¹³å°å’Œæ”¯æŒ NVIDIA GPU
çš„ç³»ç»Ÿä¸Šã€‚è¿™ç§çµæ´»æ€§ç¡®ä¿ YOLO11 å¯ç”¨äºå„ç§åº”ç”¨ï¼Œä»ç§»åŠ¨è®¾å¤‡ä¸Šçš„å®æ—¶æ£€æµ‹åˆ°äº‘ç¯å¢ƒä¸­çš„å¤æ‚åˆ†å‰²ä»»åŠ¡ã€‚æœ‰å…³éƒ¨ç½²é€‰é¡¹çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…å¯¼å‡ºæ–‡æ¡£ã€‚

##### YOLOv11 yamlæ–‡ä»¶

    
    
    # Ultralytics YOLO ğŸš€, AGPL-3.0 license
    # YOLO11 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect
    
    # Parameters
    nc: 80 # number of classes
    scales: # model compound scaling constants, i.e. 'model=yolo11n.yaml' will call yolo11.yaml with scale 'n'
      # [depth, width, max_channels]
      n: [0.50, 0.25, 1024] # summary: 319 layers, 2624080 parameters, 2624064 gradients, 6.6 GFLOPs
      s: [0.50, 0.50, 1024] # summary: 319 layers, 9458752 parameters, 9458736 gradients, 21.7 GFLOPs
      m: [0.50, 1.00, 512] # summary: 409 layers, 20114688 parameters, 20114672 gradients, 68.5 GFLOPs
      l: [1.00, 1.00, 512] # summary: 631 layers, 25372160 parameters, 25372144 gradients, 87.6 GFLOPs
      x: [1.00, 1.50, 512] # summary: 631 layers, 56966176 parameters, 56966160 gradients, 196.0 GFLOPs
    
    # YOLO11n backbone
    backbone:
      # [from, repeats, module, args]
      - [-1, 1, Conv, [64, 3, 2]] # 0-P1/2
      - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4
      - [-1, 2, C3k2, [256, False, 0.25]]
      - [-1, 1, Conv, [256, 3, 2]] # 3-P3/8
      - [-1, 2, C3k2, [512, False, 0.25]]
      - [-1, 1, Conv, [512, 3, 2]] # 5-P4/16
      - [-1, 2, C3k2, [512, True]]
      - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32
      - [-1, 2, C3k2, [1024, True]]
      - [-1, 1, SPPF, [1024, 5]] # 9
      - [-1, 2, C2PSA, [1024]] # 10
    
    # YOLO11n head
    head:
      - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
      - [[-1, 6], 1, Concat, [1]] # cat backbone P4
      - [-1, 2, C3k2, [512, False]] # 13
    
      - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
      - [[-1, 4], 1, Concat, [1]] # cat backbone P3
      - [-1, 2, C3k2, [256, False]] # 16 (P3/8-small)
    
      - [-1, 1, Conv, [256, 3, 2]]
      - [[-1, 13], 1, Concat, [1]] # cat head P4
      - [-1, 2, C3k2, [512, False]] # 19 (P4/16-medium)
    
      - [-1, 1, Conv, [512, 3, 2]]
      - [[-1, 10], 1, Concat, [1]] # cat head P5
      - [-1, 2, C3k2, [1024, True]] # 22 (P5/32-large)
    
      - [[16, 19, 22], 1, Detect, [nc]] # Detect(P3, P4, P5)
    

**YOLO11å’ŒYOLOv8 yamlæ–‡ä»¶çš„åŒºåˆ«**

![](https://i-blog.csdnimg.cn/direct/a8f3766a015c4ad2a49411ab710b3477.png)

##### æ”¹è¿›æ¨¡å—ä»£ç 

  * C3k2 

    
    
    class C3k2(C2f):
        """Faster Implementation of CSP Bottleneck with 2 convolutions."""
    
        def __init__(self, c1, c2, n=1, c3k=False, e=0.5, g=1, shortcut=True):
            """Initializes the C3k2 module, a faster CSP Bottleneck with 2 convolutions and optional C3k blocks."""
            super().__init__(c1, c2, n, shortcut, g, e)
            self.m = nn.ModuleList(
                C3k(self.c, self.c, 2, shortcut, g) if c3k else Bottleneck(self.c, self.c, shortcut, g) for _ in range(n)
            )

C3k2ï¼Œå®ƒæ˜¯å…·æœ‰ä¸¤ä¸ªå·ç§¯çš„CSPï¼ˆPartial Cross Stageï¼‰ç“¶é¢ˆæ¶æ„çš„æ›´å¿«å®ç°ã€‚

**ç±»ç»§æ‰¿ï¼š**

  * `C3k2`ç»§æ‰¿è‡ªç±»`C2f`ã€‚è¿™è¡¨æ˜`C2f`å¾ˆå¯èƒ½å®ç°äº†ç»è¿‡ä¿®æ”¹çš„åŸºæœ¬CSPç»“æ„ï¼Œè€Œ`C3k2`è¿›ä¸€æ­¥ä¼˜åŒ–æˆ–ä¿®æ”¹äº†æ­¤ç»“æ„ã€‚

**æ„é€ å‡½æ•°ï¼ˆ`__init__`ï¼‰ï¼š**

  * `c1`ï¼šè¾“å…¥é€šé“ã€‚

  * `c2`ï¼šè¾“å‡ºé€šé“ã€‚

  * `n`ï¼šç“¶é¢ˆå±‚æ•°ï¼ˆé»˜è®¤ä¸º1ï¼‰ã€‚

  * `c3k`ï¼šä¸€ä¸ªå¸ƒå°”æ ‡å¿—ï¼Œç¡®å®šæ˜¯å¦ä½¿ç”¨`C3k`å—æˆ–å¸¸è§„`Bottleneck`å—ã€‚

  * `e`ï¼šæ‰©å±•æ¯”ç‡ï¼Œæ§åˆ¶éšè—å±‚çš„å®½åº¦ï¼ˆé»˜è®¤ä¸º0.5ï¼‰ã€‚

  * `g`ï¼šåˆ†ç»„å·ç§¯çš„ç»„å½’ä¸€åŒ–å‚æ•°æˆ–ç»„æ•°ï¼ˆé»˜è®¤å€¼ä¸º 1ï¼‰ã€‚

  * `shortcut`ï¼šä¸€ä¸ªå¸ƒå°”å€¼ï¼Œç”¨äºç¡®å®šæ˜¯å¦åœ¨ç½‘ç»œä¸­åŒ…å«å¿«æ·æ–¹å¼è¿æ¥ï¼ˆé»˜è®¤å€¼ä¸º `True`ï¼‰ã€‚

**åˆå§‹åŒ–ï¼š**

  * `super().__init__(c1, c2, n, short-cut, g, e)` è°ƒç”¨çˆ¶ç±» `C2f` çš„æ„é€ å‡½æ•°ï¼Œåˆå§‹åŒ–æ ‡å‡† CSP ç»„ä»¶ï¼Œå¦‚é€šé“æ•°ã€å¿«æ·æ–¹å¼ã€ç»„ç­‰ã€‚

**æ¨¡å—åˆ—è¡¨ï¼ˆ`self.m`ï¼‰ï¼š**

  * `nn.ModuleList` å­˜å‚¨ `C3k` æˆ– `Bottleneck` æ¨¡å—ï¼Œå…·ä½“å–å†³äº `c3k` çš„å€¼ã€‚

  * å¦‚æœ `c3k` ä¸º `True`ï¼Œå®ƒä¼šåˆå§‹åŒ– `C3k` æ¨¡å—ã€‚`C3k` æ¨¡å—æ¥æ”¶ä»¥ä¸‹å‚æ•°ï¼š

  * `self.c`ï¼šé€šé“æ•°ï¼ˆæºè‡ª `C2f`ï¼‰ã€‚

  * `2`ï¼šè¿™è¡¨ç¤ºåœ¨ `C3k` å—å†…ä½¿ç”¨äº†ä¸¤ä¸ªå·ç§¯å±‚ã€‚

  * `shortcut` å’Œ `g`ï¼šä» `C3k2` æ„é€ å‡½æ•°ä¼ é€’ã€‚

  * å¦‚æœ `c3k` ä¸º `False`ï¼Œåˆ™åˆå§‹åŒ–æ ‡å‡† `Bottleneck` æ¨¡å—ã€‚

`for _ in range(n)` è¡¨ç¤ºå°†åˆ›å»º `n` ä¸ªè¿™æ ·çš„å—ã€‚

**æ€»ç»“ï¼š**

  * `C3k2` å®ç°äº† CSP ç“¶é¢ˆæ¶æ„ï¼Œå¯ä»¥é€‰æ‹©ä½¿ç”¨è‡ªå®šä¹‰ `C3k` å—ï¼ˆå…·æœ‰ä¸¤ä¸ªå·ç§¯ï¼‰æˆ–æ ‡å‡† `Bottleneck` å—ï¼Œå…·ä½“å–å†³äº `c3k` æ ‡å¿—ã€‚

  * C2PSA

    
    
    class C2PSA(nn.Module):
        """
        C2PSA module with attention mechanism for enhanced feature extraction and processing.
    
        This module implements a convolutional block with attention mechanisms to enhance feature extraction and processing
        capabilities. It includes a series of PSABlock modules for self-attention and feed-forward operations.
    
        Attributes:
            c (int): Number of hidden channels.
            cv1 (Conv): 1x1 convolution layer to reduce the number of input channels to 2*c.
            cv2 (Conv): 1x1 convolution layer to reduce the number of output channels to c.
            m (nn.Sequential): Sequential container of PSABlock modules for attention and feed-forward operations.
    
        Methods:
            forward: Performs a forward pass through the C2PSA module, applying attention and feed-forward operations.
    
        Notes:
            This module essentially is the same as PSA module, but refactored to allow stacking more PSABlock modules.
    
        Examples:
            >>> c2psa = C2PSA(c1=256, c2=256, n=3, e=0.5)
            >>> input_tensor = torch.randn(1, 256, 64, 64)
            >>> output_tensor = c2psa(input_tensor)
        """
    
        def __init__(self, c1, c2, n=1, e=0.5):
            """Initializes the C2PSA module with specified input/output channels, number of layers, and expansion ratio."""
            super().__init__()
            assert c1 == c2
            self.c = int(c1 * e)
            self.cv1 = Conv(c1, 2 * self.c, 1, 1)
            self.cv2 = Conv(2 * self.c, c1, 1)
    
            self.m = nn.Sequential(*(PSABlock(self.c, attn_ratio=0.5, num_heads=self.c // 64) for _ in range(n)))
    
        def forward(self, x):
            """Processes the input tensor 'x' through a series of PSA blocks and returns the transformed tensor."""
            a, b = self.cv1(x).split((self.c, self.c), dim=1)
            b = self.m(b)
            return self.cv2(torch.cat((a, b), 1))

`C2PSA` æ¨¡å—æ˜¯ä¸€ä¸ªè‡ªå®šä¹‰ç¥ç»ç½‘ç»œå±‚ï¼Œå¸¦æœ‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œç”¨äºå¢å¼ºç‰¹å¾æå–å’Œå¤„ç†ã€‚

**ç±»æ¦‚è¿°**

  * **ç›®çš„ï¼š**

  * `C2PSA` æ¨¡å—å¼•å…¥äº†ä¸€ä¸ªå·ç§¯å—ï¼Œåˆ©ç”¨æ³¨æ„åŠ›æœºåˆ¶æ¥æ”¹è¿›ç‰¹å¾æå–å’Œå¤„ç†ã€‚

  * å®ƒä½¿ç”¨ä¸€ç³»åˆ— `PSABlock` æ¨¡å—ï¼Œè¿™äº›æ¨¡å—å¯èƒ½ä»£è¡¨æŸç§å½¢å¼çš„ä½ç½®è‡ªæ³¨æ„åŠ› (PSA)ï¼Œå¹¶ä¸”è¯¥æ¶æ„æ—¨åœ¨å…è®¸å †å å¤šä¸ª `PSABlock` å±‚ã€‚

**æ„é€ å‡½æ•°ï¼ˆ`__init__`ï¼‰ï¼š**

  * **å‚æ•°ï¼š**

  * `c1`ï¼šè¾“å…¥é€šé“ï¼ˆå¿…é¡»ç­‰äº `c2`ï¼‰ã€‚

  * `c2`ï¼šè¾“å‡ºé€šé“ï¼ˆå¿…é¡»ç­‰äº `c1`ï¼‰ã€‚

  * `n`ï¼šè¦å †å çš„ `PSABlock` æ¨¡å—æ•°é‡ï¼ˆé»˜è®¤å€¼ä¸º 1ï¼‰ã€‚

  * `e`ï¼šæ‰©å±•æ¯”ç‡ï¼Œç”¨äºè®¡ç®—éšè—é€šé“çš„æ•°é‡ï¼ˆé»˜è®¤å€¼ä¸º 0.5ï¼‰ã€‚

  * **å±æ€§ï¼š**

  * `self.c`ï¼šéšè—é€šé“æ•°ï¼Œè®¡ç®—ä¸º `int(c1 * e)`ã€‚

  * `self.cv1`ï¼šä¸€ä¸ª `1x1` å·ç§¯ï¼Œå°†è¾“å…¥é€šé“æ•°ä» `c1` å‡å°‘åˆ° `2 * self.c`ã€‚è¿™ä¸ºå°†è¾“å…¥åˆ†æˆä¸¤éƒ¨åˆ†åšå¥½å‡†å¤‡ã€‚

  * `self.cv2`ï¼šå¦ä¸€ä¸ª `1x1` å·ç§¯ï¼Œå¤„ç†åå°†é€šé“ç»´åº¦æ¢å¤å› `c1`ã€‚

  * `self.m`ï¼šä¸€ç³»åˆ— `PSABlock` æ¨¡å—ã€‚æ¯ä¸ª `PSABlock` æ¥æ”¶ `self.c` é€šé“ï¼Œæ³¨æ„å¤´çš„æ•°é‡ä¸º `self.c // 64`ã€‚æ¯ä¸ªå—åº”ç”¨æ³¨æ„å’Œå‰é¦ˆæ“ä½œã€‚

**å‰å‘æ–¹æ³•ï¼š**

  * **è¾“å…¥ï¼š**

  * `x`ï¼Œè¾“å…¥å¼ é‡ã€‚

  * **æ“ä½œï¼š**

  1. `self.cv1(x)` åº”ç”¨ `1x1` å·ç§¯ï¼Œå°†è¾“å…¥é€šé“å¤§å°ä» `c1` å‡å°åˆ° `2 * self.c`ã€‚

  2. ç”Ÿæˆçš„å¼ é‡æ²¿é€šé“ç»´åº¦åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼Œ`a` å’Œ `b`ã€‚

  * `a`ï¼šç¬¬ä¸€ä¸ª `self.c` é€šé“ã€‚

  * `b`ï¼šå‰©ä½™çš„ `self.c` é€šé“ã€‚

  1. `b` é€šè¿‡é¡ºåºå®¹å™¨ `self.m`ï¼Œå®ƒæ˜¯ `PSABlock` æ¨¡å—çš„å †æ ˆã€‚è¿™éƒ¨åˆ†ç»è¿‡åŸºäºæ³¨æ„çš„å¤„ç†ã€‚

  2. å¤„ç†åçš„å¼ é‡ `b` ä¸ `a` è¿æ¥ã€‚

  3. `self.cv2` åº”ç”¨ `1x1` å·ç§¯ï¼Œå°†é€šé“å¤§å°æ¢å¤ä¸º `c1`ã€‚

  * **è¾“å‡ºï¼š**

  * åº”ç”¨æ³¨æ„å’Œå·ç§¯æ“ä½œåçš„å˜æ¢åçš„å¼ é‡ã€‚

**æ€»ç»“ï¼š**

  * **C2PSA** æ˜¯ä¸€ä¸ªå¢å¼ºå‹å·ç§¯æ¨¡å—ï¼Œå®ƒé€šè¿‡å †å çš„ `PSABlock` æ¨¡å—åº”ç”¨ä½ç½®è‡ªæ³¨æ„åŠ›ã€‚å®ƒæ‹†åˆ†è¾“å…¥å¼ é‡ï¼Œå°†æ³¨æ„åŠ›åº”ç”¨äºå…¶ä¸­ä¸€éƒ¨åˆ†ï¼Œç„¶åé‡æ–°ç»„åˆå¹¶é€šè¿‡æœ€ç»ˆå·ç§¯å¯¹å…¶è¿›è¡Œå¤„ç†ã€‚æ­¤ç»“æ„æœ‰åŠ©äºä»è¾“å…¥æ•°æ®ä¸­æå–å¤æ‚ç‰¹å¾ã€‚

##### ç½‘ç»œç»“æ„

![](https://i-blog.csdnimg.cn/direct/761af09befeb45adafae36b679424b26.png)

![](https://i-blog.csdnimg.cn/direct/45e481e295ad458fa7fe4c252fbd5d83.png)




### 8.200+ç§å…¨å¥—æ”¹è¿›YOLOV11åˆ›æ–°ç‚¹åŸç†è®²è§£

#### 8.1 200+ç§å…¨å¥—æ”¹è¿›YOLOV11åˆ›æ–°ç‚¹åŸç†è®²è§£å¤§å…¨

ç”±äºç¯‡å¹…é™åˆ¶ï¼Œæ¯ä¸ªåˆ›æ–°ç‚¹çš„å…·ä½“åŸç†è®²è§£å°±ä¸å…¨éƒ¨å±•å¼€ï¼Œå…·ä½“è§ä¸‹åˆ—ç½‘å€ä¸­çš„æ”¹è¿›æ¨¡å—å¯¹åº”é¡¹ç›®çš„æŠ€æœ¯åŸç†åšå®¢ç½‘å€ã€Blogã€‘ï¼ˆåˆ›æ–°ç‚¹å‡ä¸ºæ¨¡å—åŒ–æ­å»ºï¼ŒåŸç†é€‚é…YOLOv5~YOLOv11ç­‰å„ç§ç‰ˆæœ¬ï¼‰

[æ”¹è¿›æ¨¡å—æŠ€æœ¯åŸç†åšå®¢ã€Blogã€‘ç½‘å€é“¾æ¥](https://gitee.com/qunmasj/good)

![9.png](9.png)

#### 8.2 ç²¾é€‰éƒ¨åˆ†æ”¹è¿›YOLOV11åˆ›æ–°ç‚¹åŸç†è®²è§£

###### è¿™é‡ŒèŠ‚é€‰éƒ¨åˆ†æ”¹è¿›åˆ›æ–°ç‚¹å±•å¼€åŸç†è®²è§£(å®Œæ•´çš„æ”¹è¿›åŸç†è§ä¸Šå›¾å’Œ[æ”¹è¿›æ¨¡å—æŠ€æœ¯åŸç†åšå®¢é“¾æ¥](https://gitee.com/qunmasj/good)ã€å¦‚æœæ­¤å°èŠ‚çš„å›¾åŠ è½½å¤±è´¥å¯ä»¥é€šè¿‡CSDNæˆ–è€…Githubæœç´¢è¯¥åšå®¢çš„æ ‡é¢˜è®¿é—®åŸå§‹åšå®¢ï¼ŒåŸå§‹åšå®¢å›¾ç‰‡æ˜¾ç¤ºæ­£å¸¸ã€‘
ï»¿
### RCS-OSAçš„åŸºæœ¬åŸç†
å‚è€ƒè¯¥åšå®¢ï¼ŒRCSOSAï¼ˆRCS-One-Shot Aggregationï¼‰æ˜¯RCS-YOLOä¸­æå‡ºçš„ä¸€ç§ç»“æ„ï¼Œæˆ‘ä»¬å¯ä»¥å°†ä¸»è¦åŸç†æ¦‚æ‹¬å¦‚ä¸‹ï¼š

1. RCSï¼ˆReparameterized Convolution based on channel Shuffleï¼‰: ç»“åˆäº†é€šé“æ··æ´—ï¼Œé€šè¿‡é‡å‚æ•°åŒ–å·ç§¯æ¥å¢å¼ºç½‘ç»œçš„ç‰¹å¾æå–èƒ½åŠ›ã€‚

2. RCSæ¨¡å—: åœ¨è®­ç»ƒé˜¶æ®µï¼Œåˆ©ç”¨å¤šåˆ†æ”¯ç»“æ„å­¦ä¹ ä¸°å¯Œçš„ç‰¹å¾è¡¨ç¤ºï¼›åœ¨æ¨ç†é˜¶æ®µï¼Œé€šè¿‡ç»“æ„åŒ–é‡å‚æ•°åŒ–ç®€åŒ–ä¸ºå•ä¸€åˆ†æ”¯ï¼Œå‡å°‘å†…å­˜æ¶ˆè€—ã€‚

3. OSAï¼ˆOne-Shot Aggregationï¼‰: ä¸€æ¬¡æ€§èšåˆå¤šä¸ªç‰¹å¾çº§è”ï¼Œå‡å°‘ç½‘ç»œè®¡ç®—è´Ÿæ‹…ï¼Œæé«˜è®¡ç®—æ•ˆç‡ã€‚

4. ç‰¹å¾çº§è”: RCS-OSAæ¨¡å—é€šè¿‡å †å RCSï¼Œç¡®ä¿ç‰¹å¾çš„å¤ç”¨å¹¶åŠ å¼ºä¸åŒå±‚ä¹‹é—´çš„ä¿¡æ¯æµåŠ¨ã€‚

#### RCS
RCSï¼ˆåŸºäºé€šé“Shuffleçš„é‡å‚æ•°åŒ–å·ç§¯ï¼‰æ˜¯RCS-YOLOçš„æ ¸å¿ƒç»„æˆéƒ¨åˆ†ï¼Œæ—¨åœ¨è®­ç»ƒé˜¶æ®µé€šè¿‡å¤šåˆ†æ”¯ç»“æ„å­¦ä¹ ä¸°å¯Œçš„ç‰¹å¾ä¿¡æ¯ï¼Œå¹¶åœ¨æ¨ç†é˜¶æ®µé€šè¿‡ç®€åŒ–ä¸ºå•åˆ†æ”¯ç»“æ„æ¥å‡å°‘å†…å­˜æ¶ˆè€—ï¼Œå®ç°å¿«é€Ÿæ¨ç†ã€‚æ­¤å¤–ï¼ŒRCSåˆ©ç”¨é€šé“åˆ†å‰²å’Œé€šé“Shuffleæ“ä½œæ¥é™ä½è®¡ç®—å¤æ‚æ€§ï¼ŒåŒæ—¶ä¿æŒé€šé“é—´çš„ä¿¡æ¯äº¤æ¢ï¼Œè¿™æ ·åœ¨æ¨ç†é˜¶æ®µç›¸æ¯”æ™®é€šçš„3Ã—3å·ç§¯å¯ä»¥å‡å°‘ä¸€åŠçš„è®¡ç®—å¤æ‚åº¦ã€‚é€šè¿‡ç»“æ„é‡å‚æ•°åŒ–ï¼ŒRCSèƒ½å¤Ÿåœ¨è®­ç»ƒé˜¶æ®µä»è¾“å…¥ç‰¹å¾ä¸­å­¦ä¹ æ·±å±‚è¡¨ç¤ºï¼Œå¹¶åœ¨æ¨ç†é˜¶æ®µå®ç°å¿«é€Ÿæ¨ç†ï¼ŒåŒæ—¶å‡å°‘å†…å­˜æ¶ˆè€—ã€‚

#### RCSæ¨¡å—
RCSï¼ˆåŸºäºé€šé“Shuffleçš„é‡å‚æ•°åŒ–å·ç§¯ï¼‰æ¨¡å—ä¸­ï¼Œç»“æ„åœ¨è®­ç»ƒé˜¶æ®µä½¿ç”¨å¤šä¸ªåˆ†æ”¯ï¼ŒåŒ…æ‹¬1x1å’Œ3x3çš„å·ç§¯ï¼Œä»¥åŠä¸€ä¸ªç›´æ¥çš„è¿æ¥ï¼ˆIdentityï¼‰ï¼Œç”¨äºå­¦ä¹ ä¸°å¯Œçš„ç‰¹å¾è¡¨ç¤ºã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œç»“æ„è¢«é‡å‚æ•°åŒ–æˆä¸€ä¸ªå•ä¸€çš„3x3å·ç§¯ï¼Œä»¥å‡å°‘è®¡ç®—å¤æ‚æ€§å’Œå†…å­˜æ¶ˆè€—ï¼ŒåŒæ—¶ä¿æŒè®­ç»ƒé˜¶æ®µå­¦åˆ°çš„ç‰¹å¾è¡¨è¾¾èƒ½åŠ›ã€‚è¿™ä¸RCSçš„è®¾è®¡ç†å¿µç´§å¯†ç›¸è¿ï¼Œå³åœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„æƒ…å†µä¸‹æé«˜è®¡ç®—æ•ˆç‡ã€‚

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/direct/aafbf883a2a6403ea82cc23ae1484a6d.png)


ä¸Šå›¾ä¸ºå¤§å®¶å±•ç¤ºäº†RCSçš„ç»“æ„ï¼Œåˆ†ä¸ºè®­ç»ƒé˜¶æ®µï¼ˆaéƒ¨åˆ†ï¼‰å’Œæ¨ç†é˜¶æ®µï¼ˆbéƒ¨åˆ†ï¼‰ã€‚åœ¨è®­ç»ƒé˜¶æ®µï¼Œè¾“å…¥é€šè¿‡é€šé“åˆ†å‰²ï¼Œä¸€éƒ¨åˆ†è¾“å…¥ç»è¿‡RepVGGå—ï¼Œå¦ä¸€éƒ¨åˆ†ä¿æŒä¸å˜ã€‚ç„¶åé€šè¿‡1x1å·ç§¯å’Œ3x3å·ç§¯å¤„ç†RepVGGå—çš„è¾“å‡ºï¼Œä¸å¦ä¸€éƒ¨åˆ†è¾“å…¥è¿›è¡Œé€šé“Shuffleå’Œè¿æ¥ã€‚åœ¨æ¨ç†é˜¶æ®µï¼ŒåŸæ¥çš„å¤šåˆ†æ”¯ç»“æ„è¢«ç®€åŒ–ä¸ºä¸€ä¸ªå•ä¸€çš„3x3 RepConvå—ã€‚è¿™ç§è®¾è®¡å…è®¸åœ¨è®­ç»ƒæ—¶å­¦ä¹ å¤æ‚ç‰¹å¾ï¼Œåœ¨æ¨ç†æ—¶å‡å°‘è®¡ç®—å¤æ‚åº¦ã€‚é»‘è‰²è¾¹æ¡†çš„çŸ©å½¢ä»£è¡¨ç‰¹å®šçš„æ¨¡å—æ“ä½œï¼Œæ¸å˜è‰²çš„çŸ©å½¢ä»£è¡¨å¼ é‡çš„ç‰¹å®šç‰¹å¾ï¼ŒçŸ©å½¢çš„å®½åº¦ä»£è¡¨å¼ é‡çš„é€šé“æ•°ã€‚ 

#### OSA
OSAï¼ˆOne-Shot Aggregationï¼‰æ˜¯ä¸€ä¸ªå…³é”®çš„æ¨¡å—ï¼Œæ—¨åœ¨æé«˜ç½‘ç»œåœ¨å¤„ç†å¯†é›†è¿æ¥æ—¶çš„æ•ˆç‡ã€‚OSAæ¨¡å—é€šè¿‡è¡¨ç¤ºå…·æœ‰å¤šä¸ªæ„Ÿå—é‡çš„å¤šæ ·åŒ–ç‰¹å¾ï¼Œå¹¶åœ¨æœ€åçš„ç‰¹å¾æ˜ å°„ä¸­ä»…èšåˆä¸€æ¬¡æ‰€æœ‰ç‰¹å¾ï¼Œä»è€Œå…‹æœäº†DenseNetä¸­å¯†é›†è¿æ¥çš„ä½æ•ˆç‡é—®é¢˜ã€‚

OSAæ¨¡å—çš„ä½¿ç”¨æœ‰ä¸¤ä¸ªä¸»è¦ç›®çš„ï¼š

1. æé«˜ç‰¹å¾è¡¨ç¤ºçš„å¤šæ ·æ€§ï¼šOSAé€šè¿‡èšåˆå…·æœ‰ä¸åŒæ„Ÿå—é‡çš„ç‰¹å¾æ¥å¢åŠ ç½‘ç»œå¯¹äºä¸åŒå°ºåº¦çš„æ•æ„Ÿæ€§ï¼Œè¿™æœ‰åŠ©äºæå‡æ¨¡å‹å¯¹ä¸åŒå¤§å°ç›®æ ‡çš„æ£€æµ‹èƒ½åŠ›ã€‚

2. æé«˜æ•ˆç‡ï¼šé€šè¿‡åœ¨ç½‘ç»œçš„æœ€åä¸€éƒ¨åˆ†åªè¿›è¡Œä¸€æ¬¡ç‰¹å¾èšåˆï¼ŒOSAå‡å°‘äº†é‡å¤çš„ç‰¹å¾è®¡ç®—å’Œå­˜å‚¨éœ€æ±‚ï¼Œä»è€Œæé«˜äº†ç½‘ç»œçš„è®¡ç®—å’Œèƒ½æºæ•ˆç‡ã€‚

åœ¨RCS-YOLOä¸­ï¼ŒOSAæ¨¡å—è¢«è¿›ä¸€æ­¥ä¸RCSï¼ˆåŸºäºé€šé“Shuffleçš„é‡å‚æ•°åŒ–å·ç§¯ï¼‰ç›¸ç»“åˆï¼Œå½¢æˆRCS-OSAæ¨¡å—ã€‚è¿™ç§ç»“åˆä¸ä»…ä¿æŒäº†ä½æˆæœ¬çš„å†…å­˜æ¶ˆè€—ï¼Œè€Œä¸”è¿˜å®ç°äº†è¯­ä¹‰ä¿¡æ¯çš„æœ‰æ•ˆæå–ï¼Œå¯¹äºæ„å»ºè½»é‡çº§å’Œå¤§è§„æ¨¡çš„å¯¹è±¡æ£€æµ‹å™¨å°¤ä¸ºé‡è¦ã€‚

ä¸‹é¢æˆ‘å°†ä¸ºå¤§å®¶å±•ç¤ºRCS-OSAï¼ˆOne-Shot Aggregation of RCSï¼‰çš„ç»“æ„ã€‚

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/direct/d0ab884766874d739ceda9e2a9a79e29.png)


åœ¨RCS-OSAæ¨¡å—ä¸­ï¼Œè¾“å…¥è¢«åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼Œä¸€éƒ¨åˆ†ç›´æ¥é€šè¿‡ï¼Œå¦ä¸€éƒ¨åˆ†é€šè¿‡å †å çš„RCSæ¨¡å—è¿›è¡Œå¤„ç†ã€‚å¤„ç†åçš„ç‰¹å¾å’Œç›´æ¥é€šè¿‡çš„ç‰¹å¾åœ¨é€šé“æ··æ´—ï¼ˆChannel Shuffleï¼‰ååˆå¹¶ã€‚è¿™ç§ç»“æ„è®¾è®¡ç”¨äºå¢å¼ºæ¨¡å‹çš„ç‰¹å¾æå–å’Œåˆ©ç”¨æ•ˆç‡ï¼Œæ˜¯RCS-YOLOæ¶æ„ä¸­çš„ä¸€ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†æ—¨åœ¨é€šè¿‡ä¸€æ¬¡æ€§èšåˆæ¥æé«˜æ¨¡å‹å¤„ç†ç‰¹å¾çš„èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒè®¡ç®—æ•ˆç‡ã€‚

#### ç‰¹å¾çº§è”
ç‰¹å¾çº§è”ï¼ˆfeature cascadeï¼‰æ˜¯ä¸€ç§æŠ€æœ¯ï¼Œé€šè¿‡åœ¨ç½‘ç»œçš„ä¸€æ¬¡æ€§èšåˆï¼ˆone-shot aggregateï¼‰è·¯å¾„ä¸Šç»´æŒæœ‰é™æ•°é‡çš„ç‰¹å¾çº§è”æ¥å®ç°çš„ã€‚åœ¨RCS-YOLOä¸­ï¼Œç‰¹åˆ«æ˜¯åœ¨RCS-OSAï¼ˆRCS-Based One-Shot Aggregationï¼‰æ¨¡å—ä¸­ï¼Œåªä¿ç•™äº†ä¸‰ä¸ªç‰¹å¾çº§è”ã€‚

ç‰¹å¾çº§è”çš„ç›®çš„æ˜¯ä¸ºäº†å‡è½»ç½‘ç»œè®¡ç®—è´Ÿæ‹…å¹¶é™ä½å†…å­˜å ç”¨ã€‚è¿™ç§æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°èšåˆä¸åŒå±‚æ¬¡çš„ç‰¹å¾ï¼Œæé«˜æ¨¡å‹çš„è¯­ä¹‰ä¿¡æ¯æå–èƒ½åŠ›ï¼ŒåŒæ—¶é¿å…äº†è¿‡åº¦å¤æ‚åŒ–ç½‘ç»œç»“æ„æ‰€å¸¦æ¥çš„ä½æ•ˆç‡å’Œé«˜èµ„æºæ¶ˆè€—ã€‚

ä¸‹é¢ä¸ºå¤§å®¶æä¾›çš„å›¾åƒå±•ç¤ºçš„æ˜¯RCS-YOLOçš„æ•´ä½“æ¶æ„ï¼Œå…¶ä¸­åŒ…æ‹¬RCS-OSAæ¨¡å—ã€‚RCS-OSAåœ¨æ¨¡å‹ä¸­ç”¨äºå †å RCSæ¨¡å—ï¼Œä»¥ç¡®ä¿ç‰¹å¾çš„å¤ç”¨å¹¶åŠ å¼ºä¸åŒå±‚ä¹‹é—´çš„ä¿¡æ¯æµåŠ¨ã€‚å›¾ä¸­æ˜¾ç¤ºçš„å¤šå±‚RCS-OSAæ¨¡å—çš„æ’åˆ—å’Œç»„åˆåæ˜ äº†å®ƒä»¬å¦‚ä½•ä¸€èµ·å·¥ä½œä»¥ä¼˜åŒ–ç‰¹å¾ä¼ é€’å’Œæé«˜æ£€æµ‹æ€§èƒ½ã€‚

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/direct/6cb1d8b312934c8ba9f839f8dbed21fc.png)


æ€»ç»“ï¼šRCS-YOLOä¸»è¦ç”±RCS-OSAï¼ˆè“è‰²æ¨¡å—ï¼‰å’ŒRepVGGï¼ˆæ©™è‰²æ¨¡å—ï¼‰æ„æˆã€‚è¿™é‡Œçš„nä»£è¡¨å †å RCSæ¨¡å—çš„æ•°é‡ã€‚n_clsä»£è¡¨æ£€æµ‹åˆ°çš„å¯¹è±¡ä¸­çš„ç±»åˆ«æ•°é‡ã€‚å›¾ä¸­çš„IDetectæ˜¯ä»YOLOv11ä¸­å€Ÿé‰´è¿‡æ¥çš„ï¼Œè¡¨ç¤ºä½¿ç”¨äºŒç»´å·ç§¯ç¥ç»ç½‘ç»œçš„æ£€æµ‹å±‚ã€‚è¿™ä¸ªæ¶æ„é€šè¿‡å †å çš„RCSæ¨¡å—å’ŒRepVGGæ¨¡å—ï¼Œä»¥åŠä¸¤ç§ç±»å‹çš„æ£€æµ‹å±‚ï¼Œå®ç°äº†å¯¹è±¡æ£€æµ‹çš„ä»»åŠ¡ã€‚ 


### 9.ç³»ç»ŸåŠŸèƒ½å±•ç¤º

å›¾9.1.ç³»ç»Ÿæ”¯æŒæ£€æµ‹ç»“æœè¡¨æ ¼æ˜¾ç¤º

  å›¾9.2.ç³»ç»Ÿæ”¯æŒç½®ä¿¡åº¦å’ŒIOUé˜ˆå€¼æ‰‹åŠ¨è°ƒèŠ‚

  å›¾9.3.ç³»ç»Ÿæ”¯æŒè‡ªå®šä¹‰åŠ è½½æƒé‡æ–‡ä»¶best.pt(éœ€è¦ä½ é€šè¿‡æ­¥éª¤5ä¸­è®­ç»ƒè·å¾—)

  å›¾9.4.ç³»ç»Ÿæ”¯æŒæ‘„åƒå¤´å®æ—¶è¯†åˆ«

  å›¾9.5.ç³»ç»Ÿæ”¯æŒå›¾ç‰‡è¯†åˆ«

  å›¾9.6.ç³»ç»Ÿæ”¯æŒè§†é¢‘è¯†åˆ«

  å›¾9.7.ç³»ç»Ÿæ”¯æŒè¯†åˆ«ç»“æœæ–‡ä»¶è‡ªåŠ¨ä¿å­˜

  å›¾9.8.ç³»ç»Ÿæ”¯æŒExcelå¯¼å‡ºæ£€æµ‹ç»“æœæ•°æ®

![10.png](10.png)

![11.png](11.png)

![12.png](12.png)

![13.png](13.png)

![14.png](14.png)

![15.png](15.png)

![16.png](16.png)

![17.png](17.png)

### 10. YOLOv11æ ¸å¿ƒæ”¹è¿›æºç è®²è§£

#### 10.1 lsknet.py

ä»¥ä¸‹æ˜¯å¯¹ä»£ç ä¸­æœ€æ ¸å¿ƒéƒ¨åˆ†çš„æå–å’Œè¯¦ç»†æ³¨é‡Šï¼š

```python
import torch
import torch.nn as nn
from torch.nn.modules.utils import _pair as to_2tuple
from functools import partial

class Mlp(nn.Module):
    """å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰æ¨¡å—"""
    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):
        super().__init__()
        out_features = out_features or in_features  # è¾“å‡ºç‰¹å¾æ•°é»˜è®¤ä¸ºè¾“å…¥ç‰¹å¾æ•°
        hidden_features = hidden_features or in_features  # éšè—å±‚ç‰¹å¾æ•°é»˜è®¤ä¸ºè¾“å…¥ç‰¹å¾æ•°
        self.fc1 = nn.Conv2d(in_features, hidden_features, 1)  # 1x1å·ç§¯
        self.dwconv = DWConv(hidden_features)  # æ·±åº¦å·ç§¯
        self.act = act_layer()  # æ¿€æ´»å‡½æ•°
        self.fc2 = nn.Conv2d(hidden_features, out_features, 1)  # 1x1å·ç§¯
        self.drop = nn.Dropout(drop)  # Dropoutå±‚

    def forward(self, x):
        """å‰å‘ä¼ æ’­"""
        x = self.fc1(x)  # é€šè¿‡ç¬¬ä¸€ä¸ªå·ç§¯å±‚
        x = self.dwconv(x)  # é€šè¿‡æ·±åº¦å·ç§¯
        x = self.act(x)  # æ¿€æ´»
        x = self.drop(x)  # Dropout
        x = self.fc2(x)  # é€šè¿‡ç¬¬äºŒä¸ªå·ç§¯å±‚
        x = self.drop(x)  # Dropout
        return x


class Attention(nn.Module):
    """æ³¨æ„åŠ›æ¨¡å—"""
    def __init__(self, d_model):
        super().__init__()
        self.proj_1 = nn.Conv2d(d_model, d_model, 1)  # 1x1å·ç§¯
        self.activation = nn.GELU()  # æ¿€æ´»å‡½æ•°
        self.spatial_gating_unit = LSKblock(d_model)  # ç©ºé—´é—¨æ§å•å…ƒ
        self.proj_2 = nn.Conv2d(d_model, d_model, 1)  # 1x1å·ç§¯

    def forward(self, x):
        """å‰å‘ä¼ æ’­"""
        shortcut = x.clone()  # æ®‹å·®è¿æ¥
        x = self.proj_1(x)  # é€šè¿‡ç¬¬ä¸€ä¸ªå·ç§¯å±‚
        x = self.activation(x)  # æ¿€æ´»
        x = self.spatial_gating_unit(x)  # é€šè¿‡ç©ºé—´é—¨æ§å•å…ƒ
        x = self.proj_2(x)  # é€šè¿‡ç¬¬äºŒä¸ªå·ç§¯å±‚
        x = x + shortcut  # æ®‹å·®è¿æ¥
        return x


class Block(nn.Module):
    """ç½‘ç»œä¸­çš„åŸºæœ¬å—"""
    def __init__(self, dim, mlp_ratio=4., drop=0., drop_path=0., act_layer=nn.GELU):
        super().__init__()
        self.norm1 = nn.BatchNorm2d(dim)  # æ‰¹å½’ä¸€åŒ–
        self.norm2 = nn.BatchNorm2d(dim)  # æ‰¹å½’ä¸€åŒ–
        self.attn = Attention(dim)  # æ³¨æ„åŠ›æ¨¡å—
        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()  # éšæœºæ·±åº¦
        mlp_hidden_dim = int(dim * mlp_ratio)  # MLPéšè—å±‚ç»´åº¦
        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)  # MLPæ¨¡å—

    def forward(self, x):
        """å‰å‘ä¼ æ’­"""
        x = x + self.drop_path(self.attn(self.norm1(x)))  # æ·»åŠ æ³¨æ„åŠ›æ¨¡å—çš„è¾“å‡º
        x = x + self.drop_path(self.mlp(self.norm2(x)))  # æ·»åŠ MLPæ¨¡å—çš„è¾“å‡º
        return x


class LSKNet(nn.Module):
    """LSKNetæ¨¡å‹"""
    def __init__(self, img_size=224, in_chans=3, embed_dims=[64, 128, 256, 512], depths=[3, 4, 6, 3]):
        super().__init__()
        self.num_stages = len(embed_dims)  # ç½‘ç»œé˜¶æ®µæ•°

        for i in range(self.num_stages):
            # åˆ›å»ºå›¾åƒåˆ°è¡¥ä¸çš„åµŒå…¥å±‚
            patch_embed = OverlapPatchEmbed(img_size=img_size if i == 0 else img_size // (2 ** (i + 1)),
                                            in_chans=in_chans if i == 0 else embed_dims[i - 1],
                                            embed_dim=embed_dims[i])
            # åˆ›å»ºåŸºæœ¬å—
            block = nn.ModuleList([Block(dim=embed_dims[i]) for _ in range(depths[i])])
            setattr(self, f"patch_embed{i + 1}", patch_embed)  # å°†åµŒå…¥å±‚æ·»åŠ åˆ°æ¨¡å‹ä¸­
            setattr(self, f"block{i + 1}", block)  # å°†å—æ·»åŠ åˆ°æ¨¡å‹ä¸­

    def forward(self, x):
        """å‰å‘ä¼ æ’­"""
        outs = []
        for i in range(self.num_stages):
            patch_embed = getattr(self, f"patch_embed{i + 1}")
            block = getattr(self, f"block{i + 1}")
            x, H, W = patch_embed(x)  # é€šè¿‡åµŒå…¥å±‚
            for blk in block:
                x = blk(x)  # é€šè¿‡æ¯ä¸ªå—
            outs.append(x)  # ä¿å­˜è¾“å‡º
        return outs


class DWConv(nn.Module):
    """æ·±åº¦å·ç§¯æ¨¡å—"""
    def __init__(self, dim=768):
        super(DWConv, self).__init__()
        self.dwconv = nn.Conv2d(dim, dim, 3, 1, 1, bias=True, groups=dim)  # æ·±åº¦å·ç§¯

    def forward(self, x):
        """å‰å‘ä¼ æ’­"""
        x = self.dwconv(x)  # é€šè¿‡æ·±åº¦å·ç§¯
        return x


def lsknet_t(weights=''):
    """åˆ›å»ºLSKNet Tç‰ˆæœ¬çš„æ¨¡å‹"""
    model = LSKNet(embed_dims=[32, 64, 160, 256], depths=[3, 3, 5, 2])
    if weights:
        model.load_state_dict(torch.load(weights)['state_dict'])  # åŠ è½½æƒé‡
    return model

if __name__ == '__main__':
    model = lsknet_t('lsk_t_backbone-2ef8a593.pth')  # åˆ›å»ºæ¨¡å‹å¹¶åŠ è½½æƒé‡
    inputs = torch.randn((1, 3, 640, 640))  # åˆ›å»ºè¾“å…¥
    for i in model(inputs):
        print(i.size())  # æ‰“å°è¾“å‡ºå°ºå¯¸
```

### ä»£ç æ ¸å¿ƒéƒ¨åˆ†è¯´æ˜ï¼š
1. **Mlpç±»**ï¼šå®ç°äº†ä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥æœºï¼ŒåŒ…å«ä¸¤ä¸ª1x1å·ç§¯å±‚å’Œä¸€ä¸ªæ·±åº¦å·ç§¯å±‚ï¼Œæ”¯æŒæ¿€æ´»å‡½æ•°å’ŒDropoutã€‚
2. **Attentionç±»**ï¼šå®ç°äº†ä¸€ä¸ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œä½¿ç”¨äº†æ®‹å·®è¿æ¥å’Œç©ºé—´é—¨æ§å•å…ƒã€‚
3. **Blockç±»**ï¼šæ˜¯ç½‘ç»œçš„åŸºæœ¬æ„å»ºå—ï¼ŒåŒ…å«æ³¨æ„åŠ›æ¨¡å—å’ŒMLPæ¨¡å—ï¼Œå¹¶å®ç°äº†æ®‹å·®è¿æ¥ã€‚
4. **LSKNetç±»**ï¼šæ„å»ºäº†æ•´ä¸ªç½‘ç»œç»“æ„ï¼ŒåŒ…å«å¤šä¸ªé˜¶æ®µï¼Œæ¯ä¸ªé˜¶æ®µç”±åµŒå…¥å±‚å’Œå¤šä¸ªBlockç»„æˆã€‚
5. **DWConvç±»**ï¼šå®ç°äº†æ·±åº¦å·ç§¯æ“ä½œã€‚
6. **lsknet_tå‡½æ•°**ï¼šç”¨äºåˆ›å»ºLSKNet Tç‰ˆæœ¬çš„æ¨¡å‹å¹¶åŠ è½½é¢„è®­ç»ƒæƒé‡ã€‚

ä»¥ä¸Šæ˜¯å¯¹ä»£ç çš„æ ¸å¿ƒéƒ¨åˆ†è¿›è¡Œäº†æå–å’Œè¯¦ç»†æ³¨é‡Šï¼Œæ¶µç›–äº†ä¸»è¦çš„ç½‘ç»œç»“æ„å’ŒåŠŸèƒ½ã€‚

è¿™ä¸ªæ–‡ä»¶ `lsknet.py` å®ç°äº†ä¸€ä¸ªåä¸º LSKNet çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œä¸»è¦ç”¨äºå›¾åƒå¤„ç†ä»»åŠ¡ã€‚è¯¥æ¨¡å‹çš„ç»“æ„åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼Œç»“åˆäº†å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å’Œæ³¨æ„åŠ›æœºåˆ¶ã€‚ä»¥ä¸‹æ˜¯å¯¹æ–‡ä»¶ä¸­å„ä¸ªéƒ¨åˆ†çš„é€æ­¥åˆ†æå’Œè¯´æ˜ã€‚

é¦–å…ˆï¼Œæ–‡ä»¶å¯¼å…¥äº†å¿…è¦çš„åº“ï¼ŒåŒ…æ‹¬ PyTorch å’Œä¸€äº›ç›¸å…³çš„æ¨¡å—ã€‚`torch` æ˜¯æ·±åº¦å­¦ä¹ çš„æ ¸å¿ƒåº“ï¼Œ`torch.nn` æä¾›äº†æ„å»ºç¥ç»ç½‘ç»œçš„åŸºç¡€ç»„ä»¶ã€‚`timm.layers` ä¸­çš„ `DropPath` å’Œ `to_2tuple` ç”¨äºå®ç°ç‰¹å®šçš„å±‚å’ŒåŠŸèƒ½ã€‚

æ¥ä¸‹æ¥ï¼Œå®šä¹‰äº†ä¸€ä¸ªåä¸º `Mlp` çš„ç±»ï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰æ¨¡å—ã€‚å®ƒåŒ…å«ä¸¤ä¸ªå·ç§¯å±‚å’Œä¸€ä¸ªæ·±åº¦å·ç§¯å±‚ï¼ˆ`DWConv`ï¼‰ï¼Œå¹¶ä½¿ç”¨ GELU æ¿€æ´»å‡½æ•°å’Œ Dropout è¿›è¡Œæ­£åˆ™åŒ–ã€‚è¯¥æ¨¡å—çš„å‰å‘ä¼ æ’­æ–¹æ³•ä¾æ¬¡é€šè¿‡å·ç§¯ã€æ¿€æ´»ã€Dropout ç­‰æ“ä½œå¤„ç†è¾“å…¥æ•°æ®ã€‚

ç„¶åæ˜¯ `LSKblock` ç±»ï¼Œè¿™æ˜¯æ¨¡å‹çš„æ ¸å¿ƒå—ä¹‹ä¸€ã€‚å®ƒä½¿ç”¨æ·±åº¦å·ç§¯å’Œç©ºé—´å·ç§¯æ¥æå–ç‰¹å¾ï¼Œå¹¶é€šè¿‡ä¸¤ä¸ªä¸åŒçš„å·ç§¯è·¯å¾„ç”Ÿæˆæ³¨æ„åŠ›æƒé‡ã€‚æœ€ç»ˆï¼Œåˆ©ç”¨ Sigmoid å‡½æ•°å¯¹ç‰¹å¾è¿›è¡ŒåŠ æƒï¼Œè¾“å‡ºåŠ æƒåçš„ç‰¹å¾å›¾ã€‚

æ¥ç€æ˜¯ `Attention` ç±»ï¼Œå®ƒå®ç°äº†ä¸€ä¸ªæ³¨æ„åŠ›æœºåˆ¶ã€‚é€šè¿‡ä¸¤ä¸ªå·ç§¯å±‚å’Œä¸€ä¸ª `LSKblock`ï¼Œè¯¥æ¨¡å—å¯¹è¾“å…¥è¿›è¡Œå¤„ç†ï¼Œå¹¶å°†å¤„ç†åçš„ç»“æœä¸è¾“å…¥çš„å¿«æ·è¿æ¥ç›¸åŠ ï¼Œä»¥å¢å¼ºç‰¹å¾è¡¨è¾¾èƒ½åŠ›ã€‚

`Block` ç±»æ˜¯æ¨¡å‹çš„åŸºæœ¬æ„å»ºå—ï¼Œç»“åˆäº†å½’ä¸€åŒ–ã€æ³¨æ„åŠ›æœºåˆ¶å’Œ MLPã€‚å®ƒé€šè¿‡æ®‹å·®è¿æ¥å’Œ DropPath æŠ€æœ¯æ¥æé«˜æ¨¡å‹çš„ç¨³å®šæ€§å’Œæ€§èƒ½ã€‚

`OverlapPatchEmbed` ç±»ç”¨äºå°†è¾“å…¥å›¾åƒè½¬æ¢ä¸ºè¡¥ä¸åµŒå…¥ï¼Œé‡‡ç”¨å·ç§¯æ“ä½œæ¥å®ç°ã€‚è¿™ä¸€è¿‡ç¨‹å°†å›¾åƒåˆ’åˆ†ä¸ºå¤šä¸ªå°å—ï¼Œå¹¶ä¸ºæ¯ä¸ªå°å—ç”Ÿæˆç‰¹å¾è¡¨ç¤ºã€‚

`LSKNet` ç±»æ˜¯æ•´ä¸ªæ¨¡å‹çš„ä¸»ç±»ï¼Œè´Ÿè´£æ„å»ºç½‘ç»œçš„ä¸åŒé˜¶æ®µã€‚å®ƒæ ¹æ®ç»™å®šçš„å‚æ•°åˆå§‹åŒ–å¤šä¸ªåµŒå…¥å±‚ã€å—å’Œå½’ä¸€åŒ–å±‚ï¼Œå¹¶åœ¨å‰å‘ä¼ æ’­ä¸­ä¾æ¬¡å¤„ç†è¾“å…¥æ•°æ®ã€‚æ¯ä¸ªé˜¶æ®µçš„è¾“å‡ºè¢«æ”¶é›†åˆ°ä¸€ä¸ªåˆ—è¡¨ä¸­ï¼Œæœ€ç»ˆè¿”å›ã€‚

`DWConv` ç±»å®ç°äº†æ·±åº¦å·ç§¯æ“ä½œï¼Œè¿›ä¸€æ­¥å¢å¼ºäº†ç‰¹å¾æå–èƒ½åŠ›ã€‚

`update_weight` å‡½æ•°ç”¨äºæ›´æ–°æ¨¡å‹çš„æƒé‡ï¼Œç¡®ä¿åŠ è½½çš„æƒé‡ä¸æ¨¡å‹çš„ç»“æ„ç›¸åŒ¹é…ã€‚

æœ€åï¼Œ`lsknet_t` å’Œ `lsknet_s` å‡½æ•°åˆ†åˆ«ç”¨äºåˆ›å»ºä¸åŒç‰ˆæœ¬çš„ LSKNet æ¨¡å‹ï¼Œå¹¶å¯é€‰æ‹©æ€§åœ°åŠ è½½é¢„è®­ç»ƒæƒé‡ã€‚ä¸»ç¨‹åºéƒ¨åˆ†åˆ›å»ºäº†ä¸€ä¸ª LSKNet æ¨¡å‹å®ä¾‹ï¼Œå¹¶å¯¹éšæœºç”Ÿæˆçš„è¾“å…¥è¿›è¡Œå‰å‘ä¼ æ’­ï¼Œè¾“å‡ºæ¯ä¸ªé˜¶æ®µçš„ç‰¹å¾å›¾å°ºå¯¸ã€‚

æ•´ä½“æ¥çœ‹ï¼Œè¿™ä¸ªæ–‡ä»¶å®ç°äº†ä¸€ä¸ªç»“æ„å¤æ‚ã€åŠŸèƒ½å¼ºå¤§çš„å›¾åƒå¤„ç†æ¨¡å‹ï¼Œç»“åˆäº†å¤šç§æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Œé€‚ç”¨äºå„ç§è®¡ç®—æœºè§†è§‰ä»»åŠ¡ã€‚

#### 10.2 CTrans.py

ä»¥ä¸‹æ˜¯ç»è¿‡ç®€åŒ–å’Œæ³¨é‡Šçš„æ ¸å¿ƒä»£ç éƒ¨åˆ†ï¼Œä¸»è¦åŒ…æ‹¬ `ChannelTransformer`ã€`Encoder`ã€`Block_ViT`ã€`Attention_org` å’Œ `Channel_Embeddings` ç±»ã€‚æ³¨é‡Šè¯¦ç»†è§£é‡Šäº†æ¯ä¸ªéƒ¨åˆ†çš„åŠŸèƒ½å’Œå®ç°é€»è¾‘ã€‚

```python
import torch
import torch.nn as nn
import numpy as np
from torch.nn import Dropout, Softmax, LayerNorm

class Channel_Embeddings(nn.Module):
    """æ„å»ºé€šé“åµŒå…¥ï¼ŒåŒ…æ‹¬ä½ç½®åµŒå…¥å’Œè¡¥ä¸åµŒå…¥ã€‚"""
    def __init__(self, patchsize, img_size, in_channels):
        super().__init__()
        # è®¡ç®—è¡¥ä¸æ•°é‡
        n_patches = (img_size[0] // patchsize) * (img_size[1] // patchsize)
        # å®šä¹‰è¡¥ä¸åµŒå…¥å±‚
        self.patch_embeddings = nn.Sequential(
            nn.MaxPool2d(kernel_size=5, stride=5),
            nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=patchsize // 5, stride=patchsize // 5)
        )
        # å®šä¹‰ä½ç½®åµŒå…¥
        self.position_embeddings = nn.Parameter(torch.zeros(1, n_patches, in_channels))
        self.dropout = Dropout(0.1)

    def forward(self, x):
        """å‰å‘ä¼ æ’­ï¼Œè®¡ç®—åµŒå…¥ã€‚"""
        if x is None:
            return None
        x = self.patch_embeddings(x)  # è®¡ç®—è¡¥ä¸åµŒå…¥
        x = x.flatten(2).transpose(-1, -2)  # å˜å½¢ä¸º (B, n_patches, hidden)
        embeddings = x + self.position_embeddings  # åŠ ä¸Šä½ç½®åµŒå…¥
        return self.dropout(embeddings)  # è¿”å›ç»è¿‡dropoutçš„åµŒå…¥

class Attention_org(nn.Module):
    """å®ç°å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ã€‚"""
    def __init__(self, vis, channel_num):
        super(Attention_org, self).__init__()
        self.vis = vis
        self.KV_size = sum(channel_num)  # è®¡ç®—é”®å€¼å¯¹çš„å¤§å°
        self.num_attention_heads = 4  # æ³¨æ„åŠ›å¤´çš„æ•°é‡

        # å®šä¹‰æŸ¥è¯¢ã€é”®ã€å€¼çš„çº¿æ€§å˜æ¢
        self.query_layers = nn.ModuleList([nn.Linear(c, c, bias=False) for c in channel_num])
        self.key = nn.Linear(self.KV_size, self.KV_size, bias=False)
        self.value = nn.Linear(self.KV_size, self.KV_size, bias=False)
        self.softmax = Softmax(dim=3)
        self.attn_dropout = Dropout(0.1)

    def forward(self, *embeddings):
        """å‰å‘ä¼ æ’­ï¼Œè®¡ç®—æ³¨æ„åŠ›è¾“å‡ºã€‚"""
        multi_head_Q = [query(emb) for query, emb in zip(self.query_layers, embeddings) if emb is not None]
        multi_head_K = self.key(torch.cat(embeddings, dim=2))  # è®¡ç®—é”®
        multi_head_V = self.value(torch.cat(embeddings, dim=2))  # è®¡ç®—å€¼

        # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°
        attention_scores = [torch.matmul(Q, multi_head_K) / np.sqrt(self.KV_size) for Q in multi_head_Q]
        attention_probs = [self.softmax(score) for score in attention_scores]  # è®¡ç®—æ³¨æ„åŠ›æ¦‚ç‡

        # åº”ç”¨dropoutå¹¶è®¡ç®—ä¸Šä¸‹æ–‡å±‚
        context_layers = [torch.matmul(prob, multi_head_V) for prob in attention_probs]
        return context_layers  # è¿”å›ä¸Šä¸‹æ–‡å±‚

class Block_ViT(nn.Module):
    """å®ç°ä¸€ä¸ªTransformerå—ï¼ŒåŒ…æ‹¬æ³¨æ„åŠ›å’Œå‰é¦ˆç½‘ç»œã€‚"""
    def __init__(self, vis, channel_num):
        super(Block_ViT, self).__init__()
        self.attn_norms = nn.ModuleList([LayerNorm(c, eps=1e-6) for c in channel_num])  # å½’ä¸€åŒ–å±‚
        self.channel_attn = Attention_org(vis, channel_num)  # æ³¨æ„åŠ›æœºåˆ¶
        self.ffns = nn.ModuleList([Mlp(c, c * 4) for c in channel_num])  # å‰é¦ˆç½‘ç»œ

    def forward(self, *embeddings):
        """å‰å‘ä¼ æ’­ï¼Œè®¡ç®—è¾“å‡ºã€‚"""
        # è®¡ç®—æ³¨æ„åŠ›è¾“å‡º
        attn_outputs = self.channel_attn(*[norm(emb) for norm, emb in zip(self.attn_norms, embeddings)])
        # è®¡ç®—å‰é¦ˆç½‘ç»œè¾“å‡º
        outputs = [emb + attn for emb, attn in zip(embeddings, attn_outputs)]
        return outputs  # è¿”å›æ¯ä¸ªé€šé“çš„è¾“å‡º

class Encoder(nn.Module):
    """ç¼–ç å™¨ï¼ŒåŒ…å«å¤šä¸ªTransformerå—ã€‚"""
    def __init__(self, vis, channel_num):
        super(Encoder, self).__init__()
        self.layers = nn.ModuleList([Block_ViT(vis, channel_num) for _ in range(1)])  # å¤šä¸ªTransformerå—

    def forward(self, *embeddings):
        """å‰å‘ä¼ æ’­ï¼Œä¾æ¬¡é€šè¿‡æ¯ä¸ªå—ã€‚"""
        for layer in self.layers:
            embeddings = layer(*embeddings)  # é€šè¿‡æ¯ä¸ªå—
        return embeddings  # è¿”å›æœ€ç»ˆè¾“å‡º

class ChannelTransformer(nn.Module):
    """é€šé“å˜æ¢å™¨ï¼Œæ•´åˆåµŒå…¥ã€ç¼–ç å’Œé‡æ„ã€‚"""
    def __init__(self, channel_num=[64, 128, 256, 512], img_size=640, vis=False, patchSize=[40, 20, 10, 5]):
        super().__init__()
        # åˆå§‹åŒ–åµŒå…¥å±‚
        self.embeddings = nn.ModuleList([Channel_Embeddings(patch, img_size // (2 ** i), c) for i, (patch, c) in enumerate(zip(patchSize, channel_num))])
        self.encoder = Encoder(vis, channel_num)  # ç¼–ç å™¨
        self.reconstruct = nn.ModuleList([Reconstruct(c, c, kernel_size=1, scale_factor=(patch, patch)) for patch, c in zip(patchSize, channel_num)])  # é‡æ„å±‚

    def forward(self, en):
        """å‰å‘ä¼ æ’­ï¼Œå¤„ç†è¾“å…¥å¹¶è¿”å›è¾“å‡ºã€‚"""
        embeddings = [embed(en[i]) for i, embed in enumerate(self.embeddings) if en[i] is not None]
        encoded = self.encoder(*embeddings)  # ç¼–ç 
        reconstructed = [recon(enc) + en[i] for i, (recon, enc) in enumerate(zip(self.reconstruct, encoded)) if en[i] is not None]  # é‡æ„
        return reconstructed  # è¿”å›é‡æ„åçš„è¾“å‡º
```

ä»¥ä¸Šä»£ç å±•ç¤ºäº†ä¸€ä¸ªé€šé“å˜æ¢å™¨çš„åŸºæœ¬ç»“æ„ï¼ŒåŒ…å«äº†åµŒå…¥ã€æ³¨æ„åŠ›æœºåˆ¶ã€ç¼–ç å™¨å’Œé‡æ„å±‚çš„å®ç°ã€‚æ¯ä¸ªç±»å’Œæ–¹æ³•éƒ½é…æœ‰è¯¦ç»†çš„ä¸­æ–‡æ³¨é‡Šï¼Œå¸®åŠ©ç†è§£å…¶åŠŸèƒ½å’Œå®ç°é€»è¾‘ã€‚

è¿™ä¸ªç¨‹åºæ–‡ä»¶ `CTrans.py` å®ç°äº†ä¸€ä¸ªåŸºäºé€šé“çš„å˜æ¢å™¨ï¼ˆChannel Transformerï¼‰ï¼Œç”¨äºå¤„ç†å›¾åƒæ•°æ®ã€‚ç¨‹åºä¸»è¦ç”±å¤šä¸ªç±»ç»„æˆï¼Œæ¯ä¸ªç±»è´Ÿè´£ä¸åŒçš„åŠŸèƒ½ï¼Œæ•´ä½“ç»“æ„ä½“ç°äº†æ·±åº¦å­¦ä¹ æ¨¡å‹çš„æ¨¡å—åŒ–è®¾è®¡ã€‚

é¦–å…ˆï¼Œç¨‹åºå¼•å…¥äº†ä¸€äº›å¿…è¦çš„åº“ï¼ŒåŒ…æ‹¬ PyTorch å’Œ NumPyï¼Œè¿™äº›åº“ä¸ºæ·±åº¦å­¦ä¹ æ¨¡å‹çš„æ„å»ºå’Œæ•°å­¦è¿ç®—æä¾›äº†æ”¯æŒã€‚æ¥ç€ï¼Œå®šä¹‰äº†å‡ ä¸ªç±»ï¼Œæ¯ä¸ªç±»éƒ½æœ‰å…¶ç‰¹å®šçš„åŠŸèƒ½ã€‚

`Channel_Embeddings` ç±»ç”¨äºæ„å»ºå›¾åƒçš„åµŒå…¥è¡¨ç¤ºã€‚å®ƒé€šè¿‡æœ€å¤§æ± åŒ–å’Œå·ç§¯æ“ä½œå°†è¾“å…¥å›¾åƒåˆ’åˆ†ä¸ºå¤šä¸ªå°å—ï¼ˆpatchï¼‰ï¼Œå¹¶ä¸ºæ¯ä¸ªå°å—ç”Ÿæˆä½ç½®åµŒå…¥ã€‚è¯¥ç±»çš„ `forward` æ–¹æ³•è´Ÿè´£å°†è¾“å…¥æ•°æ®è¿›è¡Œå¤„ç†ï¼Œç”Ÿæˆæœ€ç»ˆçš„åµŒå…¥è¡¨ç¤ºã€‚

`Reconstruct` ç±»åˆ™ç”¨äºé‡å»ºå›¾åƒã€‚å®ƒé€šè¿‡å·ç§¯å’Œä¸Šé‡‡æ ·æ“ä½œï¼Œå°†ç»è¿‡ç¼–ç çš„ç‰¹å¾å›¾è½¬æ¢å›åŸå§‹å›¾åƒçš„ç©ºé—´åˆ†è¾¨ç‡ã€‚è¯¥ç±»çš„ `forward` æ–¹æ³•è´Ÿè´£å°†è¾“å…¥çš„åµŒå…¥æ•°æ®è½¬æ¢ä¸ºå›¾åƒç‰¹å¾ã€‚

`Attention_org` ç±»å®ç°äº†å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ã€‚å®ƒæ¥æ”¶å¤šä¸ªåµŒå…¥å¹¶è®¡ç®—æ³¨æ„åŠ›æƒé‡ï¼Œåˆ©ç”¨è¿™äº›æƒé‡å¯¹è¾“å…¥è¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œä»è€Œæå–å‡ºé‡è¦çš„ç‰¹å¾ä¿¡æ¯ã€‚è¿™ä¸ªç±»çš„ `forward` æ–¹æ³•è´Ÿè´£è®¡ç®—æŸ¥è¯¢ã€é”®ã€å€¼çš„çº¿æ€§å˜æ¢ï¼Œå¹¶è¿›è¡Œæ³¨æ„åŠ›åˆ†æ•°çš„è®¡ç®—å’Œå½’ä¸€åŒ–ã€‚

`Mlp` ç±»å®ç°äº†ä¸€ä¸ªç®€å•çš„å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ï¼Œç”¨äºç‰¹å¾çš„éçº¿æ€§å˜æ¢ã€‚å®ƒåŒ…å«ä¸¤ä¸ªå…¨è¿æ¥å±‚å’Œä¸€ä¸ªæ¿€æ´»å‡½æ•°ï¼Œèƒ½å¤Ÿå¯¹è¾“å…¥ç‰¹å¾è¿›è¡Œå¤„ç†ã€‚

`Block_ViT` ç±»ç»“åˆäº†æ³¨æ„åŠ›æœºåˆ¶å’Œå‰é¦ˆç½‘ç»œï¼Œå½¢æˆäº†ä¸€ä¸ªå®Œæ•´çš„å˜æ¢å™¨å—ã€‚å®ƒåœ¨ `forward` æ–¹æ³•ä¸­é¦–å…ˆå¯¹è¾“å…¥è¿›è¡Œå½’ä¸€åŒ–ï¼Œç„¶åé€šè¿‡æ³¨æ„åŠ›å±‚å’Œå‰é¦ˆç½‘ç»œè¿›è¡Œå¤„ç†ï¼Œæœ€åå°†ç»“æœä¸è¾“å…¥è¿›è¡Œæ®‹å·®è¿æ¥ã€‚

`Encoder` ç±»ç”±å¤šä¸ª `Block_ViT` ç»„æˆï¼Œè´Ÿè´£å°†è¾“å…¥çš„åµŒå…¥é€šè¿‡å¤šä¸ªå˜æ¢å™¨å—è¿›è¡Œç¼–ç ã€‚å®ƒçš„ `forward` æ–¹æ³•ä¾æ¬¡è°ƒç”¨æ¯ä¸ªå—ï¼Œå¹¶è¿”å›ç»è¿‡ç¼–ç çš„ç‰¹å¾ã€‚

`ChannelTransformer` ç±»æ˜¯æ•´ä¸ªæ¨¡å‹çš„æ ¸å¿ƒï¼Œè´Ÿè´£å°†è¾“å…¥å›¾åƒåˆ’åˆ†ä¸ºå¤šä¸ªé€šé“å¹¶è¿›è¡Œå¤„ç†ã€‚å®ƒåˆå§‹åŒ–äº†å¤šä¸ªåµŒå…¥å±‚ã€ç¼–ç å™¨å’Œé‡å»ºå±‚ï¼Œå¹¶åœ¨ `forward` æ–¹æ³•ä¸­ä¾æ¬¡å¤„ç†è¾“å…¥æ•°æ®ï¼Œæœ€ç»ˆè¿”å›é‡å»ºåçš„å›¾åƒã€‚

æœ€åï¼Œ`GetIndexOutput` ç±»ç”¨äºä»æ¨¡å‹çš„è¾“å‡ºä¸­æå–ç‰¹å®šç´¢å¼•çš„ç»“æœï¼Œä¾¿äºåç»­å¤„ç†ã€‚

æ•´ä½“æ¥çœ‹ï¼Œè¿™ä¸ªç¨‹åºå®ç°äº†ä¸€ä¸ªå¤æ‚çš„å›¾åƒå¤„ç†æ¨¡å‹ï¼Œåˆ©ç”¨äº†å˜æ¢å™¨çš„ç»“æ„æ¥æå–å’Œé‡å»ºå›¾åƒç‰¹å¾ï¼Œé€‚ç”¨äºå„ç§è®¡ç®—æœºè§†è§‰ä»»åŠ¡ã€‚æ¯ä¸ªæ¨¡å—çš„è®¾è®¡éƒ½ä½“ç°äº†æ·±åº¦å­¦ä¹ æ¨¡å‹çš„çµæ´»æ€§å’Œå¯æ‰©å±•æ€§ï¼Œä½¿å¾—è¯¥æ¨¡å‹èƒ½å¤Ÿæ ¹æ®éœ€è¦è¿›è¡Œè°ƒæ•´å’Œä¼˜åŒ–ã€‚

#### 10.3 SMPConv.py

ä»¥ä¸‹æ˜¯ä»£ç ä¸­æœ€æ ¸å¿ƒçš„éƒ¨åˆ†ï¼Œå¹¶é™„ä¸Šè¯¦ç»†çš„ä¸­æ–‡æ³¨é‡Šï¼š

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

# å®šä¹‰ç›¸å¯¹ä½ç½®çš„å‡½æ•°
def rel_pos(kernel_size):
    # åˆ›å»ºä¸€ä¸ªä»-1åˆ°1çš„çº¿æ€§ç©ºé—´ï¼Œå¤§å°ä¸ºkernel_size
    tensors = [torch.linspace(-1, 1, steps=kernel_size) for _ in range(2)]
    # ç”Ÿæˆç½‘æ ¼åæ ‡
    kernel_coord = torch.stack(torch.meshgrid(*tensors), dim=-0)
    kernel_coord = kernel_coord.unsqueeze(0)  # å¢åŠ ä¸€ä¸ªç»´åº¦
    return kernel_coord

# å®šä¹‰SMPå·ç§¯å±‚
class SMPConv(nn.Module):
    def __init__(self, planes, kernel_size, n_points, stride, padding, groups):
        super().__init__()

        self.planes = planes  # è¾“å‡ºé€šé“æ•°
        self.kernel_size = kernel_size  # å·ç§¯æ ¸å¤§å°
        self.n_points = n_points  # ç‚¹çš„æ•°é‡
        self.init_radius = 2 * (2/kernel_size)  # åˆå§‹åŒ–åŠå¾„

        # è®¡ç®—å·ç§¯æ ¸åæ ‡
        kernel_coord = rel_pos(kernel_size)
        self.register_buffer('kernel_coord', kernel_coord)  # æ³¨å†Œä¸ºç¼“å†²åŒº

        # æƒé‡åæ ‡åˆå§‹åŒ–
        weight_coord = torch.empty(1, n_points, 2)
        nn.init.trunc_normal_(weight_coord, std=0.2, a=-1., b=1.)  # ä½¿ç”¨æˆªæ–­æ­£æ€åˆ†å¸ƒåˆå§‹åŒ–
        self.weight_coord = nn.Parameter(weight_coord)  # æ³¨å†Œä¸ºå¯å­¦ä¹ å‚æ•°

        # åŠå¾„å‚æ•°åˆå§‹åŒ–
        self.radius = nn.Parameter(torch.empty(1, n_points).unsqueeze(-1).unsqueeze(-1))
        self.radius.data.fill_(value=self.init_radius)  # å¡«å……åˆå§‹åŠå¾„

        # æƒé‡åˆå§‹åŒ–
        weights = torch.empty(1, planes, n_points)
        nn.init.trunc_normal_(weights, std=.02)  # ä½¿ç”¨æˆªæ–­æ­£æ€åˆ†å¸ƒåˆå§‹åŒ–
        self.weights = nn.Parameter(weights)  # æ³¨å†Œä¸ºå¯å­¦ä¹ å‚æ•°

    def forward(self, x):
        # ç”Ÿæˆå·ç§¯æ ¸
        kernels = self.make_kernels().unsqueeze(1)
        x = x.contiguous()  # ç¡®ä¿è¾“å…¥å¼ é‡æ˜¯è¿ç»­çš„
        kernels = kernels.contiguous()  # ç¡®ä¿å·ç§¯æ ¸å¼ é‡æ˜¯è¿ç»­çš„

        # æ ¹æ®è¾“å…¥æ•°æ®ç±»å‹é€‰æ‹©ä¸åŒçš„å·ç§¯å®ç°
        if x.dtype == torch.float32:
            x = _DepthWiseConv2dImplicitGEMMFP32.apply(x, kernels)  # FP32çš„æ·±åº¦å·ç§¯
        elif x.dtype == torch.float16:
            x = _DepthWiseConv2dImplicitGEMMFP16.apply(x, kernels)  # FP16çš„æ·±åº¦å·ç§¯
        else:
            raise TypeError("Only support fp32 and fp16, get {}".format(x.dtype))  # æŠ›å‡ºä¸æ”¯æŒçš„ç±»å‹é”™è¯¯
        return x        

    def make_kernels(self):
        # è®¡ç®—å·ç§¯æ ¸çš„å·®å¼‚
        diff = self.weight_coord.unsqueeze(-2) - self.kernel_coord.reshape(1, 2, -1).transpose(1, 2)  # [1, n_points, kernel_size^2, 2]
        diff = diff.transpose(2, 3).reshape(1, self.n_points, 2, self.kernel_size, self.kernel_size)  # é‡å¡‘å½¢çŠ¶
        diff = F.relu(1 - torch.sum(torch.abs(diff), dim=2) / self.radius)  # è®¡ç®—ReLUæ¿€æ´»çš„å·®å¼‚
        
        # è®¡ç®—æœ€ç»ˆçš„å·ç§¯æ ¸
        kernels = torch.matmul(self.weights, diff.reshape(1, self.n_points, -1))  # [1, planes, kernel_size*kernel_size]
        kernels = kernels.reshape(1, self.planes, *self.kernel_coord.shape[2:])  # [1, planes, kernel_size, kernel_size]
        kernels = kernels.squeeze(0)  # å»æ‰å¤šä½™çš„ç»´åº¦
        kernels = torch.flip(kernels.permute(0, 2, 1), dims=(1,))  # ç¿»è½¬å·ç§¯æ ¸
        return kernels

# å®šä¹‰SMPCNNæ¨¡å—
class SMPCNN(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride, groups, n_points=None, n_points_divide=4):
        super().__init__()
        self.kernel_size = kernel_size
        if n_points is None:
            n_points = int((kernel_size**2) // n_points_divide)  # è®¡ç®—ç‚¹çš„æ•°é‡

        padding = kernel_size // 2  # è®¡ç®—å¡«å……
        self.smp = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,
                           stride=stride, padding=padding, dilation=1, groups=groups, n_points=n_points)

        self.small_kernel = 5  # å°å·ç§¯æ ¸å¤§å°
        self.small_conv = Conv(in_channels, out_channels, self.small_kernel, stride, self.small_kernel // 2, groups, act=False)  # å°å·ç§¯å±‚

    def forward(self, inputs):
        out = self.smp(inputs)  # é€šè¿‡SMPå·ç§¯å±‚
        out += self.small_conv(inputs)  # åŠ ä¸Šå°å·ç§¯å±‚çš„è¾“å‡º
        return out
```

### ä»£ç æ ¸å¿ƒéƒ¨åˆ†è¯´æ˜ï¼š
1. **SMPConv ç±»**ï¼šå®ç°äº†ä¸€ä¸ªè‡ªå®šä¹‰çš„å·ç§¯å±‚ï¼Œä½¿ç”¨äº†ç›¸å¯¹ä½ç½®ç¼–ç å’ŒåŠ¨æ€å·ç§¯æ ¸ç”Ÿæˆã€‚
2. **make_kernels æ–¹æ³•**ï¼šè®¡ç®—å·ç§¯æ ¸çš„ç”Ÿæˆè¿‡ç¨‹ï¼Œä½¿ç”¨æƒé‡å’Œä½ç½®å·®å¼‚ç”Ÿæˆæœ€ç»ˆçš„å·ç§¯æ ¸ã€‚
3. **SMPCNN ç±»**ï¼šç»“åˆäº†è‡ªå®šä¹‰çš„SMPå·ç§¯å±‚å’Œä¸€ä¸ªå°å·ç§¯å±‚ï¼Œå½¢æˆä¸€ä¸ªå¤åˆå·ç§¯æ¨¡å—ã€‚

è¿™ä¸ªç¨‹åºæ–‡ä»¶ `SMPConv.py` å®ç°äº†ä¸€ç§ç‰¹æ®Šçš„å·ç§¯ç¥ç»ç½‘ç»œæ¨¡å—ï¼Œä¸»è¦åŒ…å«äº† `SMPConv`ã€`SMPCNN`ã€`SMPCNN_ConvFFN` å’Œ `SMPBlock` ç­‰ç±»ã€‚æ–‡ä»¶ä¸­ä½¿ç”¨äº† PyTorch æ¡†æ¶ï¼Œç»“åˆäº†ä¸€äº›æ·±åº¦å­¦ä¹ ä¸­çš„é«˜çº§æŠ€æœ¯ï¼Œå¦‚æ·±åº¦å¯åˆ†ç¦»å·ç§¯ã€æ­£åˆ™åŒ–å’Œæ®‹å·®è¿æ¥ç­‰ã€‚

é¦–å…ˆï¼Œ`SMPConv` ç±»æ˜¯æ ¸å¿ƒçš„å·ç§¯æ¨¡å—ï¼Œå®ƒåœ¨åˆå§‹åŒ–æ—¶æ¥å—å¤šä¸ªå‚æ•°ï¼ŒåŒ…æ‹¬è¾“å‡ºé€šé“æ•°ã€å·ç§¯æ ¸å¤§å°ã€é‡‡æ ·ç‚¹æ•°ã€æ­¥å¹…ã€å¡«å……å’Œåˆ†ç»„æ•°ã€‚å®ƒä½¿ç”¨ `rel_pos` å‡½æ•°ç”Ÿæˆå·ç§¯æ ¸çš„ç›¸å¯¹ä½ç½®ï¼Œå¹¶é€šè¿‡æ³¨å†Œç¼“å†²åŒºçš„æ–¹å¼ä¿å­˜è¿™äº›ä½ç½®ã€‚æƒé‡åæ ‡å’ŒåŠå¾„ä¹Ÿåœ¨åˆå§‹åŒ–æ—¶è¢«å®šä¹‰å¹¶ä½œä¸ºå¯è®­ç»ƒå‚æ•°ã€‚`forward` æ–¹æ³•ä¸­ï¼Œè¾“å…¥å¼ é‡é€šè¿‡ `make_kernels` æ–¹æ³•ç”Ÿæˆçš„å·ç§¯æ ¸è¿›è¡Œå·ç§¯æ“ä½œï¼Œæ”¯æŒ FP32 å’Œ FP16 æ•°æ®ç±»å‹çš„è¾“å…¥ã€‚

`make_kernels` æ–¹æ³•è´Ÿè´£è®¡ç®—å·ç§¯æ ¸çš„å…·ä½“å½¢çŠ¶å’Œæƒé‡ã€‚å®ƒé€šè¿‡è®¡ç®—æƒé‡åæ ‡ä¸å·ç§¯æ ¸åæ ‡ä¹‹é—´çš„å·®å¼‚ï¼Œåˆ©ç”¨ ReLU æ¿€æ´»å‡½æ•°å¤„ç†è¿™äº›å·®å¼‚ï¼Œå¹¶æœ€ç»ˆç”Ÿæˆå®é™…çš„å·ç§¯æ ¸ã€‚

`get_conv2d` å‡½æ•°æ ¹æ®è¾“å…¥å‚æ•°å†³å®šä½¿ç”¨ `SMPConv` è¿˜æ˜¯æ ‡å‡†çš„ `nn.Conv2d`ï¼Œè¿™ä½¿å¾—ä»£ç åœ¨éœ€è¦æ—¶èƒ½å¤Ÿçµæ´»åˆ‡æ¢ã€‚

`SMPCNN` ç±»æ˜¯ä¸€ä¸ªç»„åˆæ¨¡å—ï¼Œå®ƒå°† `SMPConv` å’Œä¸€ä¸ªå°å·ç§¯å±‚ç»“åˆåœ¨ä¸€èµ·ï¼Œå½¢æˆä¸€ä¸ªæ›´å¤æ‚çš„å·ç§¯ç»“æ„ã€‚è¿™ä¸ªç»“æ„é€šè¿‡å°†è¾“å…¥åˆ†åˆ«ä¼ å…¥ä¸¤ä¸ªå·ç§¯å±‚å¹¶ç›¸åŠ ï¼Œå¢å¼ºäº†ç‰¹å¾æå–çš„èƒ½åŠ›ã€‚

`SMPCNN_ConvFFN` ç±»å®ç°äº†ä¸€ä¸ªå‰é¦ˆç½‘ç»œï¼ŒåŒ…å«ä¸¤ä¸ªé€ç‚¹å·ç§¯å±‚å’Œä¸€ä¸ª GELU æ¿€æ´»å‡½æ•°ã€‚å®ƒçš„è®¾è®¡ä½¿å¾—å¯ä»¥åœ¨ç‰¹å¾å›¾ä¸Šè¿›è¡Œéçº¿æ€§å˜æ¢ï¼Œå¹¶é€šè¿‡æ®‹å·®è¿æ¥å°†è¾“å…¥ä¸è¾“å‡ºç›¸åŠ ï¼Œä¿æŒä¿¡æ¯çš„æµåŠ¨ã€‚

`SMPBlock` ç±»åˆ™æ˜¯ä¸€ä¸ªæ›´é«˜å±‚æ¬¡çš„æ¨¡å—ï¼Œç»“åˆäº†é€ç‚¹å·ç§¯å’Œå¤§å·ç§¯æ ¸çš„ç»“æ„ã€‚å®ƒé€šè¿‡æ®‹å·®è¿æ¥å’Œ DropPath æŠ€æœ¯å¢å¼ºäº†ç½‘ç»œçš„è¡¨è¾¾èƒ½åŠ›å’Œç¨³å®šæ€§ã€‚

æ­¤å¤–ï¼Œæ–‡ä»¶ä¸­è¿˜å®šä¹‰äº†ä¸€äº›è¾…åŠ©å‡½æ•°ï¼Œå¦‚ `conv_bn` å’Œ `conv_bn_relu`ï¼Œç”¨äºç®€åŒ–å·ç§¯å±‚å’Œæ‰¹å½’ä¸€åŒ–å±‚çš„ç»„åˆåˆ›å»ºè¿‡ç¨‹ã€‚`fuse_bn` å‡½æ•°åˆ™ç”¨äºå°†å·ç§¯å±‚å’Œæ‰¹å½’ä¸€åŒ–å±‚èåˆï¼Œä»¥æé«˜æ¨ç†é€Ÿåº¦ã€‚

æ€»çš„æ¥è¯´ï¼Œè¿™ä¸ªæ–‡ä»¶å®ç°äº†ä¸€ä¸ªçµæ´»ä¸”é«˜æ•ˆçš„å·ç§¯ç¥ç»ç½‘ç»œæ¨¡å—ï¼Œé€‚ç”¨äºå„ç§è®¡ç®—æœºè§†è§‰ä»»åŠ¡ï¼Œèƒ½å¤Ÿé€šè¿‡è‡ªå®šä¹‰çš„å·ç§¯æ“ä½œå’Œç»“æ„è®¾è®¡æ¥æå‡æ¨¡å‹çš„æ€§èƒ½ã€‚

#### 10.4 test_selective_scan_easy.py

ä»¥ä¸‹æ˜¯ç»è¿‡ç®€åŒ–å’Œæ³¨é‡Šçš„æ ¸å¿ƒä»£ç éƒ¨åˆ†ï¼š

```python
import torch
import torch.nn.functional as F

def selective_scan_easy(us, dts, As, Bs, Cs, Ds, delta_bias=None, delta_softplus=False, return_last_state=False, chunksize=64):
    """
    é€‰æ‹©æ€§æ‰«æå‡½æ•°ï¼Œæ‰§è¡Œä¸€ç³»åˆ—çš„çŠ¶æ€æ›´æ–°å’Œè¾“å‡ºè®¡ç®—ã€‚
    
    å‚æ•°ï¼š
    us: è¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶ä¸º (B, G * D, L)
    dts: æ—¶é—´å¢é‡å¼ é‡ï¼Œå½¢çŠ¶ä¸º (B, G * D, L)
    As: ç³»æ•°å¼ é‡ï¼Œå½¢çŠ¶ä¸º (G * D, N)
    Bs: ç³»æ•°å¼ é‡ï¼Œå½¢çŠ¶ä¸º (B, G, N, L)
    Cs: ç³»æ•°å¼ é‡ï¼Œå½¢çŠ¶ä¸º (B, G, N, L)
    Ds: åç½®å¼ é‡ï¼Œå½¢çŠ¶ä¸º (G * D)
    delta_bias: å¯é€‰çš„åç½®è°ƒæ•´ï¼Œå½¢çŠ¶ä¸º (G * D)
    delta_softplus: æ˜¯å¦åº”ç”¨softplusæ¿€æ´»
    return_last_state: æ˜¯å¦è¿”å›æœ€åçš„çŠ¶æ€
    chunksize: æ¯æ¬¡å¤„ç†çš„æ—¶é—´æ­¥é•¿

    è¿”å›ï¼š
    è¾“å‡ºå¼ é‡ï¼Œå½¢çŠ¶ä¸º (B, G * D, L)ï¼Œæˆ–åŒ…å«è¾“å‡ºå’Œæœ€åçŠ¶æ€çš„å…ƒç»„
    """
    
    def selective_scan_chunk(us, dts, As, Bs, Cs, hprefix):
        """
        å¤„ç†ä¸€ä¸ªæ—¶é—´å—çš„é€‰æ‹©æ€§æ‰«æã€‚
        
        å‚æ•°ï¼š
        us: è¾“å…¥å¼ é‡çš„ä¸€ä¸ªå—
        dts: æ—¶é—´å¢é‡å¼ é‡çš„ä¸€ä¸ªå—
        As, Bs, Cs: ç³»æ•°å¼ é‡
        hprefix: å‰ä¸€ä¸ªçŠ¶æ€
        
        è¿”å›ï¼š
        è¾“å‡ºå¼ é‡å’Œå½“å‰çŠ¶æ€
        """
        ts = dts.cumsum(dim=0)  # è®¡ç®—æ—¶é—´å¢é‡çš„ç´¯ç§¯å’Œ
        Ats = torch.einsum("gdn,lbgd->lbgdn", As, ts).exp()  # è®¡ç®—æŒ‡æ•°
        rAts = Ats  # å½’ä¸€åŒ–
        duts = dts * us  # è®¡ç®—è¾“å…¥ä¸æ—¶é—´å¢é‡çš„ä¹˜ç§¯
        dtBus = torch.einsum("lbgd,lbgn->lbgdn", duts, Bs)  # è®¡ç®—ä¸­é—´ç»“æœ
        hs_tmp = rAts * (dtBus / rAts).cumsum(dim=0)  # æ›´æ–°çŠ¶æ€
        hs = hs_tmp + Ats * hprefix.unsqueeze(0)  # ç»“åˆå‰ä¸€ä¸ªçŠ¶æ€
        ys = torch.einsum("lbgn,lbgdn->lbgd", Cs, hs)  # è®¡ç®—è¾“å‡º
        return ys, hs

    # æ•°æ®ç±»å‹å’Œå½¢çŠ¶è°ƒæ•´
    dtype = torch.float32
    dts = dts.to(dtype)
    if delta_bias is not None:
        dts += delta_bias.view(1, -1, 1).to(dtype)
    if delta_softplus:
        dts = F.softplus(dts)

    # å¤„ç†è¾“å…¥å’Œç³»æ•°å¼ é‡çš„å½¢çŠ¶
    Bs = Bs.unsqueeze(1) if len(Bs.shape) == 3 else Bs
    Cs = Cs.unsqueeze(1) if len(Cs.shape) == 3 else Cs
    B, G, N, L = Bs.shape
    us = us.view(B, G, -1, L).permute(3, 0, 1, 2).to(dtype)
    dts = dts.view(B, G, -1, L).permute(3, 0, 1, 2).to(dtype)
    As = As.view(G, -1, N).to(dtype)
    Bs = Bs.permute(3, 0, 1, 2).to(dtype)
    Cs = Cs.permute(3, 0, 1, 2).to(dtype)

    oys = []  # è¾“å‡ºåˆ—è¡¨
    hprefix = us.new_zeros((B, G, -1, N), dtype=dtype)  # åˆå§‹åŒ–å‰ä¸€ä¸ªçŠ¶æ€
    for i in range(0, L, chunksize):
        ys, hs = selective_scan_chunk(
            us[i:i + chunksize], dts[i:i + chunksize], 
            As, Bs[i:i + chunksize], Cs[i:i + chunksize], hprefix
        )
        oys.append(ys)  # æ”¶é›†è¾“å‡º
        hprefix = hs[-1]  # æ›´æ–°å‰ä¸€ä¸ªçŠ¶æ€

    oys = torch.cat(oys, dim=0)  # åˆå¹¶æ‰€æœ‰è¾“å‡º
    oys = oys.permute(1, 2, 3, 0).view(B, -1, L)  # è°ƒæ•´è¾“å‡ºå½¢çŠ¶

    return oys if not return_last_state else (oys, hprefix.view(B, -1, N).float())  # è¿”å›è¾“å‡ºæˆ–è¾“å‡ºå’Œæœ€åçŠ¶æ€
```

### ä»£ç è¯´æ˜ï¼š
1. **å‡½æ•°å®šä¹‰**ï¼š`selective_scan_easy` æ˜¯ä¸»è¦çš„é€‰æ‹©æ€§æ‰«æå‡½æ•°ï¼Œæ¥å—å¤šä¸ªè¾“å…¥å¼ é‡å’Œå‚æ•°ï¼Œè¿”å›è®¡ç®—åçš„è¾“å‡ºã€‚
2. **å†…éƒ¨å‡½æ•°**ï¼š`selective_scan_chunk` å¤„ç†è¾“å…¥çš„ä¸€ä¸ªæ—¶é—´å—ï¼Œè®¡ç®—çŠ¶æ€å’Œè¾“å‡ºã€‚
3. **æ•°æ®é¢„å¤„ç†**ï¼šè°ƒæ•´è¾“å…¥å¼ é‡çš„å½¢çŠ¶å’Œæ•°æ®ç±»å‹ï¼Œç¡®ä¿å®ƒä»¬ç¬¦åˆè®¡ç®—è¦æ±‚ã€‚
4. **å¾ªç¯å¤„ç†**ï¼šå¯¹è¾“å…¥çš„æ¯ä¸ªæ—¶é—´å—è¿›è¡Œå¤„ç†ï¼Œæ›´æ–°çŠ¶æ€å¹¶æ”¶é›†è¾“å‡ºã€‚
5. **è¾“å‡º**ï¼šæœ€ç»ˆè¿”å›è®¡ç®—ç»“æœï¼Œå¯ä»¥é€‰æ‹©æ˜¯å¦è¿”å›æœ€åçš„çŠ¶æ€ã€‚

è¿™ä¸ªç®€åŒ–çš„ç‰ˆæœ¬ä¿ç•™äº†æ ¸å¿ƒé€»è¾‘ï¼Œå¹¶æ·»åŠ äº†è¯¦ç»†çš„ä¸­æ–‡æ³¨é‡Šï¼Œä»¥å¸®åŠ©ç†è§£ä»£ç çš„åŠŸèƒ½å’Œæµç¨‹ã€‚

è¿™ä¸ªç¨‹åºæ–‡ä»¶ `test_selective_scan_easy.py` å®ç°äº†ä¸€ä¸ªåä¸º `selective_scan_easy` çš„å‡½æ•°ï¼Œå¹¶ä¸”åŒ…å«äº†ä¸ä¹‹ç›¸å…³çš„æµ‹è¯•ä»£ç ã€‚è¯¥å‡½æ•°ä¸»è¦ç”¨äºå¤„ç†åºåˆ—æ•°æ®çš„é€‰æ‹©æ€§æ‰«ææ“ä½œï¼Œé€šå¸¸ç”¨äºç¥ç»ç½‘ç»œä¸­çš„çŠ¶æ€æ›´æ–°å’Œåºåˆ—å»ºæ¨¡ã€‚

é¦–å…ˆï¼Œç¨‹åºå¯¼å…¥äº†ä¸€äº›å¿…è¦çš„åº“ï¼ŒåŒ…æ‹¬ `torch`ã€`math`ã€`functools` å’Œ `pytest`ï¼Œä»¥åŠ `einops` ç”¨äºå¼ é‡é‡æ’ã€‚æ¥ç€ï¼Œå®šä¹‰äº†ä¸€ä¸ª `selective_scan_easy` å‡½æ•°ï¼Œè¯¥å‡½æ•°æ¥å—å¤šä¸ªå‚æ•°ï¼ŒåŒ…æ‹¬è¾“å…¥åºåˆ— `us`ã€æ—¶é—´å·® `dts`ã€çŸ©é˜µ `As`ã€`Bs`ã€`Cs` å’Œ `Ds`ï¼Œä»¥åŠä¸€äº›å¯é€‰å‚æ•°å¦‚ `delta_bias` å’Œ `delta_softplus`ã€‚

åœ¨ `selective_scan_easy` å‡½æ•°å†…éƒ¨ï¼Œé¦–å…ˆå®šä¹‰äº†ä¸€ä¸ªåµŒå¥—å‡½æ•° `selective_scan_chunk`ï¼Œç”¨äºå¤„ç†æ•°æ®å—çš„é€‰æ‹©æ€§æ‰«æã€‚è¯¥å‡½æ•°å®ç°äº†ä¸€ä¸ªæ•°å­¦æ¨¡å‹ï¼Œé€šè¿‡å¯¹è¾“å…¥æ•°æ®è¿›è¡Œç´¯åŠ å’Œå˜æ¢ï¼Œè®¡ç®—å‡ºå½“å‰çŠ¶æ€å’Œè¾“å‡ºã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒä½¿ç”¨äº†å¼ é‡çš„é€æ­¥ç´¯åŠ å’ŒçŸ©é˜µä¹˜æ³•æ¥å®ç°è¿™ä¸€è¿‡ç¨‹ã€‚

æ¥ä¸‹æ¥ï¼Œç¨‹åºå¯¹è¾“å…¥æ•°æ®è¿›è¡Œäº†ç±»å‹è½¬æ¢å’Œå½¢çŠ¶è°ƒæ•´ï¼Œä»¥ç¡®ä¿å®ƒä»¬ç¬¦åˆåç»­è®¡ç®—çš„è¦æ±‚ã€‚å‡½æ•°ä½¿ç”¨ `torch.einsum` è¿›è¡Œé«˜æ•ˆçš„å¼ é‡æ“ä½œï¼Œå¹¶åœ¨å¾ªç¯ä¸­åˆ†å—å¤„ç†è¾“å…¥æ•°æ®ï¼Œä»¥é™ä½å†…å­˜æ¶ˆè€—ã€‚

æœ€åï¼Œå‡½æ•°è¿”å›è®¡ç®—ç»“æœï¼Œå¹¶æ ¹æ® `return_last_state` å‚æ•°å†³å®šæ˜¯å¦è¿”å›æœ€åçš„çŠ¶æ€ã€‚

æ­¤å¤–ï¼Œç¨‹åºè¿˜å®šä¹‰äº†ä¸€ä¸ª `SelectiveScanEasy` ç±»ï¼Œç»§æ‰¿è‡ª `torch.autograd.Function`ï¼Œç”¨äºå®ç°è‡ªå®šä¹‰çš„å‰å‘å’Œåå‘ä¼ æ’­æ“ä½œã€‚è¯¥ç±»çš„ `forward` æ–¹æ³•å®ç°äº†ä¸ `selective_scan_easy` å‡½æ•°ç›¸ä¼¼çš„é€»è¾‘ï¼Œè€Œ `backward` æ–¹æ³•åˆ™å®ç°äº†åå‘ä¼ æ’­ç®—æ³•ï¼Œä»¥è®¡ç®—æ¢¯åº¦ã€‚

åœ¨æ–‡ä»¶çš„æœ€åéƒ¨åˆ†ï¼Œå®šä¹‰äº†ä¸€äº›æµ‹è¯•å‡½æ•°ï¼Œä½¿ç”¨ `pytest` è¿›è¡Œå•å…ƒæµ‹è¯•ã€‚è¿™äº›æµ‹è¯•å‡½æ•°ä¼šæ ¹æ®ä¸åŒçš„è¾“å…¥å‚æ•°ç»„åˆï¼ŒéªŒè¯ `selective_scan_easy` å‡½æ•°çš„è¾“å‡ºæ˜¯å¦ç¬¦åˆé¢„æœŸï¼Œå¹¶æ£€æŸ¥æ¢¯åº¦è®¡ç®—çš„æ­£ç¡®æ€§ã€‚

æ€»ä½“è€Œè¨€ï¼Œè¿™ä¸ªç¨‹åºæ–‡ä»¶å®ç°äº†ä¸€ä¸ªé«˜æ•ˆçš„é€‰æ‹©æ€§æ‰«ææœºåˆ¶ï¼Œé€‚ç”¨äºå¤„ç†åºåˆ—æ•°æ®çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¹¶é€šè¿‡æµ‹è¯•ç¡®ä¿å…¶åŠŸèƒ½çš„æ­£ç¡®æ€§ã€‚

æ³¨æ„ï¼šç”±äºæ­¤åšå®¢ç¼–è¾‘è¾ƒæ—©ï¼Œä¸Šé¢â€œ10.YOLOv11æ ¸å¿ƒæ”¹è¿›æºç è®²è§£â€ä¸­éƒ¨åˆ†ä»£ç å¯èƒ½ä¼šä¼˜åŒ–å‡çº§ï¼Œä»…ä¾›å‚è€ƒå­¦ä¹ ï¼Œä»¥â€œ11.å®Œæ•´è®­ç»ƒ+Webå‰ç«¯ç•Œé¢+200+ç§å…¨å¥—åˆ›æ–°ç‚¹æºç ã€æ•°æ®é›†è·å–â€çš„å†…å®¹ä¸ºå‡†ã€‚

### 11.å®Œæ•´è®­ç»ƒ+Webå‰ç«¯ç•Œé¢+200+ç§å…¨å¥—åˆ›æ–°ç‚¹æºç ã€æ•°æ®é›†è·å–

![19.png](19.png)


# [ä¸‹è½½é“¾æ¥ï¼šhttps://mbd.pub/o/bread/Zp6YlJtt](https://mbd.pub/o/bread/Zp6YlJtt)